{
 "metadata": {
  "name": "",
  "signature": "sha256:cdae28a78d28e7d725997c3319424892b7019904cc73f99948819a8950fc0c86"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Project 4. Latent Semantic Analysis and Semi-Supervised Learning #\n",
      "\n",
      "In this assignment, you will use singular value decomposition (SVD) to learn about lexical semantics. You will have to work with \"big\" data: big enough that you will have to think carefully about speed and memory. Of particular importance will **sparse** matrix representations of your data. Some particular functions and classes you might need:\n",
      "\n",
      "- [scipy.sparse.csr_matrix](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) - matrix in compressed sparse row format\n",
      "- [scipy.sparse.diags](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.diags.html) - method for creating sparse diagonal matrices\n",
      "- [diagonal()](http://docs.scipy.org/doc/numpy/reference/generated/numpy.diagonal.html) - get the diagonal of a matrix\n",
      "- [sklearn.preprocessing.normalize](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) - efficiently normalize sparse matrices\n",
      "- [scipy.sparse.csr_matrix.asfptype()](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.asfptype.html) - upcast matrix to a floating point format\n",
      "- [scipy.cluster.vq.kmeans2](http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans2.html#scipy.cluster.vq.kmeans2) - Classify a set of observations into k clusters using the k-means algorithm\n",
      "- [numpy.argsort](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html) - returns the indices that would sort an array\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from scipy.sparse.linalg import svds\n",
      "from scipy.sparse import hstack, diags, csr_matrix\n",
      "from sklearn.preprocessing import normalize\n",
      "import numpy as np\n",
      "import csv\n",
      "import scorer, operator\n",
      "from collections import defaultdict, Counter\n",
      "import matplotlib.pyplot as plt\n",
      "%pylab --no-import-all inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "Populating the interactive namespace from numpy and matplotlib"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def csv2csr(filename):\n",
      "    word = []\n",
      "    context = []\n",
      "    count = []\n",
      "    with open(filename,'rb') as infile:\n",
      "        reader = csv.reader(infile)\n",
      "        for row in reader:\n",
      "            word.append(int(row[0]))\n",
      "            context.append(int(row[1]))\n",
      "            count.append(int(row[2]))\n",
      "    return csr_matrix((count,(word,context)))\n",
      "\n",
      "def readVocab(filename):\n",
      "    vocab = []\n",
      "    with open(filename,'rb') as vocabfile:\n",
      "        for line in vocabfile:\n",
      "            vocab.append(line.split()[0])\n",
      "    index = dict(zip(range(0,len(vocab)),vocab)) #from numbers to words\n",
      "    inv_index = {j:i for i,j in index.items()} #from words to numbers\n",
      "    return index,inv_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Loading the Data ##\n",
      "\n",
      "Call **C=proj4_starter.csv2csr('doc_trips.csv')** to load a sparse matrix $C$ of a word-document counts. The cell $c[i,j]$ should \n",
      "hold the count of word $i$ in document $j$.\n",
      "\n",
      "Call **idx, iidx=proj4_starter.readVocab('vocab.10k')** to load the vocabulary. You get two **dict** objects, mapping between words \n",
      "and indices in the matrix $C$. In **C[iidx['Obama'],:]**, you have the document counts for the word *Obama*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Load data and dictionaries\n",
      "'''\n",
      "C = csv2csr('doc_trips.csv')\n",
      "idx, iidx = readVocab('vocab.10k')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Cosine Similarity ##\n",
      "\n",
      "The *cosine similarity* of two vectors $u$ and $v$ is defined as \n",
      "$$\\frac{\\sum_{i}u_iv_i}{\\sqrt{\\sum_iu_i^2\\sum_iv_i^2}}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 1** Consider the words *coffee, play, crazy, facebook*, and *hermana* (Spanish for *sister*). For each of them, find \n",
      "the 10 most similar words according to cosine similarity of the rows in $C$.\n",
      "\n",
      "**Hint** The size of the vocabulary is nearly 10,000 words. You do not want to compute and store the entire $10K\\times 10K$ matrix \n",
      "of cosine similarities. Rather, you want to compute them on demand for a given row of the matrix. You may also want to do some\n",
      "precomputation to take care of denominator in advance. Whatever you do, don't lose the sparsity of $C$, or you will not be able \n",
      "to store it.\n",
      "\n",
      "**Sanity check** For *facebook*, the top 5 words I get are *facebook page on twitter deleted*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here is the word list\n",
      "word_list = ['coffee','play','crazy','facebook','hermana']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalizeRow(x):\n",
      "    '''\n",
      "    Normalize each row of x\n",
      "    \n",
      "    Args:\n",
      "    x - data matrix\n",
      "    Return:\n",
      "    row-normalized x\n",
      "    '''\n",
      "    return diags(np.array(1./(1e-6+np.sqrt(x.multiply(x).sum(axis=1))))[:,0],0) * x\n",
      "    \n",
      "\n",
      "def computeCosSimPerWord(word_idx, x):\n",
      "    '''\n",
      "    For a given data matrix, compute cosine similarity between the word vocab[word_index] and all words \n",
      "    (including itself)\n",
      "    \n",
      "    Args:\n",
      "    word_idx - the index of one word\n",
      "    x - data matrix\n",
      "    Return:\n",
      "    The cosine similarity between x[word_idx,:] and all other words\n",
      "    '''\n",
      "    print word_idx\n",
      "    word = x[word_idx,:].transpose()\n",
      "    output = x*word\n",
      "    simMat = np.array(output.todense())[:,0]\n",
      "  #  simMat[word_idx] = -1\n",
      "    return simMat\n",
      "## \n",
      "normalizedC = normalizeRow(C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printSimilarWords(x, word_list, sim_func, vocab=idx, ivocab=iidx):\n",
      "    '''\n",
      "    Print similar words for each word in \"word_list\". \n",
      "    The similarity between words are computed from data matrix \"x\"\n",
      "    The way of measuring similarity is defined in \"sim_func\"\n",
      "    '''\n",
      "    \n",
      "    for word in word_list:\n",
      "        print word, ':', \n",
      "        word_idx = ivocab[word]\n",
      "        sim_idx = np.argsort(-sim_func(word_idx, x))[:10]\n",
      "        for word2_idx in sim_idx:\n",
      "            print vocab[word2_idx],\n",
      "        print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print the results\n",
      "'''\n",
      "printSimilarWords(normalizedC, word_list, sim_func=computeCosSimPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : 1389\n",
        "coffee"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mug shop starbucks drinking drink cup cups and large \n",
        "play : 1664\n",
        "play"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to games game the and with soccer i . \n",
        "crazy : 6716\n",
        "crazy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 's how that it shit is drives i . \n",
        "facebook : 5246\n",
        "facebook"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " page on twitter deleted instagram status compra post whatsapp \n",
        "hermana : 3727\n",
        "hermana"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mi concha la y de tu con regalo que \n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 2 ** Come up with five words of your own that you think might be interesting, and list the top 10 most similar \n",
      "for each. Try to choose a few different types of words, such as verbs, adjectives, names, emotions, abbreviations, or \n",
      "alternative spellings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Add five words to the following list\n",
      "'''\n",
      "additional_word_list = ['bro',':)','love','#usa' ,'best']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print the results\n",
      "'''\n",
      "printSimilarWords(normalizedC, additional_word_list, sim_func=computeCosSimPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bro : 93\n",
        "bro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " @u mudik thanks you lil . birthday ! my \n",
        ":) : 8457\n",
        ":)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " )) ) @u ))) \" : follback selamat semoga \n",
        "love : 1634\n",
        "love"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " i you much and follow my . please me \n",
        "#usa : 8854\n",
        "#usa"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " #bel supporting fully #por howard #worldcup ahhhhh england vs \n",
        "best : 341\n",
        "best"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the friend ever is of friends . my in \n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Document Co-occurence ##\n",
      "\n",
      "Compute the document co-occurence matrix $D$, where $d_{i,j}$ is the probability $P(w_j|w_i)$ that word $j$ appears in a tweet, \n",
      "given that word $i$ appears. To do this, first compute the co-occurence counts $CC^\\top$. Substract the diagonal, then normalize \n",
      "each row. \n",
      "\n",
      "Note: it is possible to smooth this probability, but if you naively add some number to the matrix, you will lose sparsity \n",
      "and memory will blow up. Smoothing is not required for this assignment."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 3** For each of the 10 examples above (my five words and your five words), find the 10 most similar words \n",
      "according to cosine similarity of the rows of $D$.\n",
      "\n",
      "**Sanity check** For *facebook*, the 5 words I get are *facebook instagram twitter tv youtube*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_list = word_list + additional_word_list\n",
      "\n",
      "def computeCooccurMatrix(C):\n",
      "    '''\n",
      "    Compute the co-occurence matrix D from C\n",
      "    '''\n",
      "    AsymCo = C*C.transpose()\n",
      "    dia = diags(AsymCo.diagonal(),0)\n",
      "   \n",
      "    Co = AsymCo - dia\n",
      "    return Co\n",
      "\n",
      "D = computeCooccurMatrix(C)\n",
      "normalizedD = normalizeRow(D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print the results\n",
      "'''\n",
      "\n",
      "printSimilarWords(normalizedD, word_list, sim_func=computeCosSimPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : 1389\n",
        "coffee"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new today drinking getting food after day eating water \n",
        "play : 1664\n",
        "play"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " down be back pass show beat them up run \n",
        "crazy : 6716\n",
        "crazy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " weird sad not stupid damn actually cool about over \n",
        "facebook : 5246\n",
        "facebook"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " instagram twitter tv youtube tumblr 100 note ex insta \n",
        "hermana : 3727\n",
        "hermana"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " abuela hermano vieja novio novia viejo padre familia corazon \n",
        "bro : 93\n",
        "bro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aww mate aye ok ;-) aw x hun yea \n",
        ":) : 8457\n",
        ":)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ;) ^^ hahah haha hahahah ahahaha ^_^ ahaha ooo \n",
        "love : 1634\n",
        "love"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " miss can mean know hope see loved missed won't \n",
        "#usa : 8854\n",
        "#usa"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " #worldcup2014 germany usa exciting mexico #worldcup game england belgium \n",
        "best : 341\n",
        "best"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " most biggest same during first greatest worst against spirit \n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 4. Latent Semantic Analysis ##\n",
      "\n",
      "Perform truncated SVD (**scipy.sparse.linalg.svds**) to obtain $\\mathbf{USV}^\\top\\approx \\mathbf{C}$ using $K=10$. \n",
      "Each row vector $\\mathbf{u}_i$\n",
      "is a description of the word $i$. You can compute similarity between pairs of words using the Euclidean norm \n",
      "$\\|\\mathbf{u}_i-\\mathbf{u}_j\\|_2$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 4(a)** For each of the 10 examples above, find the 10 most similar words according to Euclidean distance in $\\mathbf{U}$\n",
      "\n",
      "**Sanity check** For *facebook*, the top 5 words are *facebook ex harry calls snap*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeEuclidDistPerWord(word_idx, U):\n",
      " #   print word_idx\n",
      "    '''\n",
      "    Compute the Euclid distance bwteen word vocab[word_idx] and all words \n",
      "    (including itself). Then, return the top 10 similar word indices\n",
      "    \n",
      "    Args:\n",
      "      word_idx - the word index\n",
      "      U - latent representation of words\n",
      "    Return:\n",
      "        the **negative**  Euclidean distance between U[word_idx,:] and all other words,\n",
      "        so that more similar words have higher values\n",
      "    '''\n",
      "    points = U[0]\n",
      "    single_point = U[0][word_idx]\n",
      "    dist = (points - single_point)**2\n",
      "    dist = np.sum(dist, axis=1)\n",
      "    dist = np.sqrt(dist)\n",
      "  \n",
      "    return -dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Once you finish the function computeEuclidDistPerWord, run the following code directly to print results\n",
      "'''\n",
      "Cfp= C.asfptype()\n",
      "U = svds(Cfp, 10)\n",
      "#print U[0]\n",
      "printSimilarWords(U, word_list, sim_func=computeEuclidDistPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : coffee drinking paper cat eating apparently turned short dress months \n",
        "play : play looking everyone anyone another start coming use enough away \n",
        "crazy : crazy gone stupid sad cool yet funny perfect must once \n",
        "facebook : facebook ex harry calls snap instagram ...... uh 18 fav \n",
        "hermana : hermana unas minutos colegio toca novia verte gana juego unos \n",
        "bro : bro xx hi :-) babe mate shut ill proud xxx \n",
        ":) : :) 3 :( ( ) hahaha ah :d :' apa \n",
        "love : love know can don't when how do if why what \n",
        "#usa : #usa bay passing members leaves stadium guard seats security begins \n",
        "best : best world same only most game first way thing ever \n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 4(b) ** Now compute the same SVD with $K=50$, and again find the 10 most similar words according to Euclidean distance $U$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print results\n",
      "'''\n",
      "U = svds(Cfp, 50)\n",
      "\n",
      "printSimilarWords(U, word_list, sim_func=computeEuclidDistPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : coffee tea wine four gas midnight starbucks service wedding six \n",
        "play : play hang run chill we're agree nobody kids fight games \n",
        "crazy : crazy weird stupid actually af dumb serious dead ugly dude \n",
        "facebook : facebook instagram focus ig netflix earth floor fb tl list \n",
        "hermana : hermana sonrisa llevo plata jajajaj realidad arriba jajaj vuelta novia \n",
        "bro : bro mate bruh broke homie wit blow lil turnt showed \n",
        ":) : :) ) ( ya aku !! yg :' di yang \n",
        "love : love follow am please miss hate thank happy hope wish \n",
        "#usa : #usa nation belgium gaza americans shite election #worldcup bodies hockey \n",
        "best : best most worst world god by favorite team family ever \n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 5 ** Now compute the SVD of the matrix $\\mathbf{D}$, using with $K = 10$, and $K = 50$. Report \n",
      "the most similar words to each of the example words according to Euclidean distance in $U$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print results\n",
      "'''\n",
      "D= D.asfptype()\n",
      "U = svds(D, 10)\n",
      "\n",
      "printSimilarWords(U, word_list, sim_func=computeEuclidDistPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : coffee upset leaving crap bullshit boring nights loud losing reading \n",
        "play : play anyone use looking move forward stop win went music \n",
        "crazy : crazy gone mind forever kind hot full fun sick fucked \n",
        "facebook : facebook 24 david alcohol simple 17 traffic 22 priority med \n",
        "hermana : hermana entrar esperar juego colegio saben unico culpa minutos unas \n",
        "bro : bro :-) dm hi hahah nah hey xx birthday true \n",
        ":) : :) ) :d hahaha haha :p :( aja di apa \n",
        "love : love know can think don't when like hate wanna can't \n",
        "#usa : #usa shooting racist heavy unbelievable review cancelled idiots choices justice \n",
        "best : best same world from game only by most first thing \n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to print results\n",
      "'''\n",
      "U = svds(D, 50)\n",
      "\n",
      "printSimilarWords(U, word_list, sim_func=computeEuclidDistPerWord)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : coffee cream tea ice cheese starbucks chicken chips cake pack \n",
        "play : play run drive beach beat party walk ball join stay \n",
        "crazy : crazy af weird dumb dying freaking gay crying confused stupid \n",
        "facebook : facebook instagram ig netflix focus couch nerves insta floor fb \n",
        "hermana : hermana vieja verga abuela peli loca ropa tarea prueba siesta \n",
        "bro : bro xx mate hahah !!!! yay dude congrats yea #ff \n",
        ":) : :) =) ;; !! ;) yes !!! x great birthday \n",
        "love : love miss thank please follow happy birthday you're hope make \n",
        "#usa : #usa rangers manchester #sochi2014 belgium champs results festival rush tech \n",
        "best : best most world same first end by worst only rest \n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 6 ** Overall, which set of synonyms looks best to you? \n",
      "Count how many of the top 10 synonyms for each of the 5 example words \n",
      "(the ones I picked) have the same majority part of speech (e.g., *play* is a verb) as the cue word.\n",
      "Use the tagset from the [Twitter POS paper](http://www.cc.gatech.edu/~jeisenst/papers/acl2012pos.pdf)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*\n",
      "Overall Latent Semantic Analysis on Document Co-Occurence (D) with K = 50 , gave the best results. In general increasing K gives better results. Lower K tends to give more of words occuring in a document as compared to synonyms. Between C and D, D gives more percentage of words that are similar to the word.\n",
      "\n",
      "coffee : coffee cream tea ice cheese chicken chips cake pack - 9.\n",
      "\n",
      "play: play run drive beat party walk join stay  - 8.\n",
      "\n",
      "crazy: crazy af weird dumb freaking gay stupid - 7 .\n",
      "\n",
      "facebook: facebook instagram ig netflix couch insta fb - 7 .\n",
      "\n",
      "hermana: hermana vieja verga abuela peli loca ropa tarea prueba siesta  - 8 .\n",
      "\n",
      "\n",
      "coffee    (C10,5) (C50,7) (D10,4) (D50,9)\n",
      "\n",
      "play      (C10,4) (C50,6) (D10,8) (D50,8)\n",
      "\n",
      "crazy     (C10,6) (C50,6) (D10,5) (D50,7)\n",
      "\n",
      "facebook  (C10,4) (C50,8) (D10,2) (D50,7)\n",
      "\n",
      "hermana   (C10,6) (C50,5) (D10,4) (D50,8)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5. Local Context ##\n",
      "\n",
      "Local context captures the frequency with which words appear in each others\u2019 immediate context. We have provided a CSV file (succ_trips_50k.csv)  in which each line contains a triple $\\langle x,y,z\\rangle$, \n",
      "where $x$ and $y$ are term IDs and $z$ is the count of times where $y$ immediately follows $x$ . \n",
      "The vocabulary has now increased to 50K words. There is an associated vocabulary file, **vocab.50k**.\n",
      "\n",
      "Build a sparse matrix $\\mathbf{E}$ from these triples. Normalize the rows of $\\mathbf{E}$, such that $e_{i,j}=\\frac{n(i,j)}{n(i)}$, \n",
      "the probability of seeing word $j$ given that you have just seen word $i$. \n",
      "Mow form a matrix $\\mathbf{F} = [\\mathbf{E}~ \\mathbf{E}\u2019]$ by horizontally concatenating the normalized matrix $\\mathbf{E}$. \n",
      "You will perform sparse singular value decomposition on $\\mathbf{F}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalizeProb(x):\n",
      "    '''\n",
      "    Normalize each row of x\n",
      "    \n",
      "    Args:\n",
      "    x - data matrix\n",
      "    Return:\n",
      "    row-normalized x\n",
      "    '''\n",
      "    return diags(np.array(1./(1e-6+x.sum(axis=1)))[:,0],0) * x\n",
      "    \n",
      "\n",
      "def constructF(E):\n",
      "    '''\n",
      "    Finish the following code to construct F from E\n",
      "    '''\n",
      "    ## Your code here\n",
      "    ET = E.transpose()\n",
      "    F = hstack([normalizeProb(E),normalizeProb(ET)])\n",
      "    return F\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Load new dataset and the corresponding dictionaries\n",
      "'''\n",
      "idx_50, iidx_50 = readVocab('vocab.50k')\n",
      "E = csv2csr('succ_trips_50k.csv')\n",
      "F = constructF(E)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 7 ** For $K = 10$ and $K = 100$ compute the top 10 synonyms for each of your ten words. \n",
      "\n",
      "** Sanity check ** For *facebook*, I get: *facebook cnn duncan nicole consistent* from $K = 10$\n",
      "and *facebook instagram youtube ig twitter* from $K = 100$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to get the results with K=10\n",
      "'''\n",
      "U_f = svds(F, 10)\n",
      "printSimilarWords(U_f, word_list, sim_func=computeEuclidDistPerWord, vocab=idx_50, ivocab=iidx_50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : coffee finger tax quiet speech friday coach common scoring cold \n",
        "play : play fall lay comes pay rely kick lose live perform \n",
        "crazy : crazy reported smiling crying beth sucked died crashed suspended kane \n",
        "facebook : facebook cnn duncan nicole consistent ronaldo smith suarez injured bio \n",
        "hermana : hermana aun estaba se aguanta pega duran todavia tampoco estudie \n",
        "bro : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bro ffs whyyyyy keri bruh fra begonnen we'll jill maybe \n",
        ":) : :) yakkk motif batak ngo #chsi kizim ;) :( :/ \n",
        "love : love hate remember miss believe commenting cum led movin gma \n",
        "#usa : #usa fighters kem hijab cooling offline buyers geoffrey s5 benieuwd \n",
        "best : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best latest bucs bottom most ultimate inbetweeners laziest fastest highest \n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to get the results with K=100\n",
      "'''\n",
      "U_f = svds(F,100)\n",
      "printSimilarWords(U_f, word_list, sim_func=computeEuclidDistPerWord, vocab=idx_50, ivocab=iidx_50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coffee pizza tea beer food softball fruit curry milk alcohol \n",
        "play : play drive dance fly survive be swim murder sing win \n",
        "crazy : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "crazy scary who cool gay else everyone cooler elton that \n",
        "facebook : facebook instagram youtube ig twitter tumblr wednesday netflix holiday wallay \n",
        "hermana : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hermana abuela hermano hna piace amorcito sobrina yetmez tocca sobrino \n",
        "bro : bro mate buddy brah c'mon tho homie babe pal jesus \n",
        ":) : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ":) ;) #katchup dilamar :: karar eweh espace remix #janoskianstour \n",
        "love : love hadn't know loveee can hope jusy did suggest crave \n",
        "#usa : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#usa #arg 00000kt usa #jpn #ned #bestfandom2014 af #0ff *-* \n",
        "best : best ultimate biggest floor world bible scariest highest across latest \n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 8 ** Again, count the proportion of proposed synonyms that have the same POS as \n",
      "the cue words that I selected. Does local context or document context do better at matching the POS of the cue words? Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*\n",
      "\n",
      "In general, local Context is giving better results, specially for verbs, nouns. The reason is that if in a sentence , we have :\"Let us have coffee\" \"Anyone can have tea\" , then association of have with tea and coffee is more relevant than rest of the sentences. So for most of the sentences which follow verb noun agreement , local context works better. However, for the word which is adjective like crazy, then both gave similar results, infact document context gave better synonyms like stupid, which was not captured in local context. \n",
      "It needs to be noted that even K 1 perform really well for local context.\n",
      "\n",
      "Counts for POS are as follows:\n",
      "\n",
      "coffee : coffee pizza tea beer food softball fruit curry milk alcohol - 10.\n",
      "\n",
      "play: play drive dance fly survive be swim murder sing win  - 10.\n",
      "\n",
      "crazy: crazy scary cool gay cooler   - 5 .\n",
      "\n",
      "facebook: facebook instagram youtube ig twitter tumblr wednesday netflix holiday - 9 .\n",
      "\n",
      "hermana: hermana abuela hermano hna piace amorcito sobrina yetmez  - 8 .\n",
      "\n",
      "\n",
      "coffee (L10,6) (L100,10) \n",
      "\n",
      "play (L10,10) (L100,10) \n",
      "\n",
      "crazy (L10,6) (L100,5)\n",
      "\n",
      "facebook (L10,7) (L100,9)\n",
      "\n",
      "hermana (L10,3) (L100,8)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 6. Clustering ##\n",
      "\n",
      "Perform KMeans clustering on the rows of the latent semantic representation $US$ that you obtained in the previous section \n",
      "(recall that $U$ describes the words; $S$ scales the latent factors by importance).\n",
      "\n",
      "Let the number of clusters equal 200. You may use an existing KMeans clustering library, \n",
      "or you may write your own. I used **scipy.cluster.vq.kmeans2**, and manually set the number of iterations to 100.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.cluster.vq import kmeans2, kmeans\n",
      "\n",
      "n_clusters = 200\n",
      "'''\n",
      "Your code here for clustering \n",
      "'''\n",
      "U_f = svds(F, 100)\n",
      "words = U_f[0]\n",
      "scale = U_f[1]\n",
      "data = words*scale\n",
      "out = kmeans2(data,n_clusters,100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print out[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  5  68 163 ...,  24 146 116]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 9(a)**  Use pyplot.hist to make a [histogram](http://en.wikipedia.org/wiki/Histogram) of the sizes of each cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#somehow compute the sizes\n",
      "sizes =out[1]\n",
      "k=plt.hist(sizes,bins = 200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD9CAYAAABazssqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109f18210>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster = [0]*200\n",
      "for data in sizes:\n",
      "    cluster[data] = cluster[data] +1\n",
      "l=plt.hist(cluster)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD9CAYAAAC7iRw+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109f2c410>"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print k[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 184  111   32  272   78  197  111  135   64  421   62  156    0   50  524\n",
        "  105   57  167  113  112  404  319  320    0   77    0   88  356  746  106\n",
        "  315  810   68  168  389  210  442   11  181  440  103  148   29  117  189\n",
        "   22    5   90   82   14   99  161  283  276  117   91  179  141  188  280\n",
        "   29  513  391   41  162  769 1181   55  507    7   40   33  676  200 1040\n",
        "  135   60  122   64   17  395  100  313  192   64  106   31   94  170  205\n",
        "  279    0  258 1063  118   30   78  350   19  267  332  153  170  483   93\n",
        "  149  230  156  223   29    0   10  391  173  153  223  486  219    0  225\n",
        "  144  124  213  171  305   75   44  875  383  212  525  347  460  458  134\n",
        "  484  420   79    0  224  128   93  277  386  384  132  854  218  109  134\n",
        "  138  200   35  604  151  352   12   97   89  635   99  262  152  632  141\n",
        "  772   63  264   12 1680  606  285   75  235   54  206  407  264 1474  452\n",
        "   59  207  357  152  167   56  219    0   83   12  158    0  114  187  146\n",
        "   30   73   82   22  174]\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 9(b)** Out of your ten examples words (you can exclude *hermana*), pick the one in the smallest cluster. \n",
      "Examine the words in this cluster, and list three that you think belong, and three that you think do not belong."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print word_list\n",
      "smallest =5000\n",
      "cluster = 0\n",
      "mwrd =\"a\"\n",
      "for word in word_list:\n",
      "    if word != 'hermana':\n",
      "        if smallest > k[0][sizes[iidx_50[word]]]:\n",
      "            smallest = k[0][sizes[iidx_50[word]]]\n",
      "            cluster = sizes[iidx_50[word]]\n",
      "            mwrd = word\n",
      "print smallest\n",
      "print cluster\n",
      "print \"Word**** =>  \"  + mwrd\n",
      "count = -1\n",
      "for swords in sizes:\n",
      "    count=count+1\n",
      "    if swords == cluster: \n",
      "         print idx_50[count]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['coffee', 'play', 'crazy', 'facebook', 'hermana', 'bro', ':)', 'love', '#usa', 'best']\n",
        "149\n",
        "105\n",
        "Word**** =>  love\n",
        "could\n",
        "neeeeeed\n",
        "wonder\n",
        "concur\n",
        "havnt\n",
        "am\n",
        "adore\n",
        "strongly\n",
        "reckon\n",
        "can\n",
        "truthfully\n",
        "mean\n",
        "think\n",
        "looooove\n",
        "feel\n",
        "couldve\n",
        "phoned\n",
        "overhear\n",
        "thought\n",
        "can't\n",
        "didn't\n",
        "knowww\n",
        "tuoi\n",
        "googled\n",
        "crave\n",
        "love\n",
        "h8\n",
        "swore\n",
        "snorted\n",
        "sware\n",
        "dammm\n",
        "calculated\n",
        "couldnt\n",
        "don't...\n",
        "woulda\n",
        "shall\n",
        "knew\n",
        "whenever\n",
        "need\n",
        "piedi\n",
        "begged\n",
        "migliori\n",
        "weighed\n",
        "frankly\n",
        "wouldve\n",
        "didn't..\n",
        "agree\n",
        "figured\n",
        "swear\n",
        "typed\n",
        "miei\n",
        "capelli\n",
        "swea\n",
        "shouldn't.\n",
        "loveee\n",
        "would've\n",
        "tink\n",
        "wore\n",
        "dyed\n",
        "realized\n",
        "stg\n",
        "wouldnt\n",
        "loathe\n",
        "wuv\n",
        "loled\n",
        "napped\n",
        "promise\n",
        "dislike\n",
        "yawned\n",
        "ddnt\n",
        "can't!\n",
        "can't,\n",
        "cannot\n",
        "personally\n",
        "dreamt\n",
        "knoww\n",
        "alls\n",
        "quoted\n",
        "wished\n",
        "everytime\n",
        "haven't\n",
        "wouldn't\n",
        "swam\n",
        "forgot\n",
        "cant\n",
        "didnt\n",
        "whn\n",
        "studied\n",
        "wasn't.\n",
        "duno\n",
        "loooove\n",
        "dont\n",
        "dreamed\n",
        "prefer\n",
        "looove\n",
        "soldi\n",
        "hoped\n",
        "guarantee\n",
        "don't\n",
        "misss\n",
        "havent\n",
        "beleive\n",
        "counted\n",
        "can't.\n",
        "bawled\n",
        "didn't,\n",
        "wish\n",
        "hate\n",
        "apologize\n",
        "#honestyhour\n",
        "volunteer\n",
        "#twitterversary\n",
        "overthink\n",
        "dunno\n",
        "shouldnt\n",
        "alrdy\n",
        "lovee\n",
        "nominate\n",
        "wana\n",
        "needa\n",
        "kuz\n",
        "didn't.\n",
        "sometimes\n",
        "admire\n",
        "hope\n",
        "s2g\n",
        "apologized\n",
        "bet\n",
        "hadda\n",
        "don't!\n",
        "shiver\n",
        "juat\n",
        "don't,\n",
        "don't.\n",
        "don't?\n",
        "coglioni\n",
        "couldn't\n",
        "assumed\n",
        "miss\n",
        "could've\n",
        "pictured\n",
        "guess\n",
        "ma'am.\n",
        "knowwww\n",
        "won't.\n",
        "gotchu\n",
        "jinxed\n",
        "suggest\n",
        "despise\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inc = 0\n",
      "for swords in sizes:\n",
      "    if swords ==3:\n",
      "        inc = inc +1\n",
      "print inc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "*Answer*\n",
      "Here we have taken the word love, which basically expresses feelings (verb)\n",
      "\n",
      "Words which belong are lovee feel adore lovee luv like admire.\n",
      "\n",
      "Words which dont belong to this category  are #earthquake literally  ma'am overthink needa  overhear "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 7650 Only: Semi-Supervised Learning ##\n",
      "\n",
      "Now use the clusters from the previous part as features in your implementation from either pset 2 or pset 3.\n",
      "\n",
      "If you already used other word clusters as features in the bakeoff, you still need to do this part with the clusters that you've built yourself in this problem set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7.1  POS Tagger ###\n",
      "\n",
      "Add the word clusters as features in your Twitter POS tagger. Start with your best performing tagger from **Project 2** (based on the dev data). Add a feature for each cluster/tag pair, e.g. C174/N, C189/V, etc. You will then compute the accuracy with training sets of various sizes, comparing the performance of your model with and without the cluster features."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 11 (Option A)** Build training sets including the first 50, 100, 200, 500, and 1000 *sentences* (not words). \n",
      "Train your tagger on each training set, using your original features, and plot the accuracy on the development set. \n",
      "Then retrain you tagger, including the new word cluster features, and plot accuracy on the development set on the same plot. \n",
      "Run for at least 10 iterations in each case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Data processing code\n",
      "\"\"\"\n",
      "def conllSeqGenerator(input_file,max_insts=1000000):\n",
      "    \"\"\" \n",
      "    return an instance generator for a filename.\n",
      "    \n",
      "    The generator yields lists of words and tags.  \n",
      "    No need to change this\n",
      "    \"\"\"\n",
      "    cur_words = []\n",
      "    cur_tags = []\n",
      "    num_insts = 0\n",
      "    with open(input_file) as instances:\n",
      "        for line in instances:\n",
      "            if len(line.rstrip()) == 0:\n",
      "                if len(cur_words) > 0:\n",
      "                    num_insts += 1\n",
      "                    yield cur_words,cur_tags\n",
      "                    cur_words = []\n",
      "                    cur_tags = []\n",
      "            else:\n",
      "                parts = line.rstrip().split()\n",
      "                cur_words.append(parts[0])\n",
      "                if len(parts)>1:\n",
      "                    cur_tags.append(parts[1])\n",
      "                else: cur_tags.append(unknown)\n",
      "        if len(cur_words)>0: \n",
      "            num_insts += 1\n",
      "            yield cur_words,cur_tags\n",
      "## Define the file names\n",
      "trainfile = 'oct27.train'\n",
      "devfile = 'oct27.dev'\n",
      "testfile = 'oct27.test' # You do not have this for now\n",
      "unknown = \"**UNKNOWN**\"\n",
      "# for convenience\n",
      "tr_all = []\n",
      "for i,(words,tags) in enumerate(conllSeqGenerator(trainfile)):\n",
      "    tr_all.append((words,tags))\n",
      "alltags = set()\n",
      "for i,(words, tags) in enumerate(tr_all):    \n",
      "    for tag in tags:\n",
      "        alltags.add(tag)\n",
      "start_tag = '--START--'\n",
      "end_tag = '--END--'\n",
      "trans ='--T--'\n",
      "emit = '--E--'\n",
      "offset = '--OFF--'\n",
      "cluster = '--cluster--'\n",
      "def wordFeatures(words,tag,prev_tag,m):\n",
      "    '''\n",
      "    :param words: a list of words\n",
      "    :type words: list\n",
      "    :param tag: a tag\n",
      "    :type tag: string\n",
      "    :type prev_tag: string\n",
      "    :type m: int\n",
      "    '''\n",
      " #   print offset,tag\n",
      "    out = {(offset,tag):1}\n",
      "    if m < len(words): #we can have m = M, for the transition to the end state\n",
      "        out[(emit,tag,words[m])]=1\n",
      "    return out\n",
      "sent = 'they can can fish'.split()\n",
      "wordFeatures(sent,'V','V',2)\n",
      "\n",
      "curr_suffix = '--curr-suff--'\n",
      "prev_suffix = '--prev-suff--'\n",
      "def wordCharFeatures(words,tag,prev_tag,m):\n",
      "    output = wordFeatures(words,tag,prev_tag,m) #start with the features from wordFeatures\n",
      "    # add your code here\n",
      "    output[(curr_suffix,tag,words[m][-1])] =1\n",
      "    if(m>0):\n",
      "         output[(prev_suffix,tag,words[m-1][-1])] =1\n",
      "    return output\n",
      "# use this to find the highest-scoring label\n",
      "argmax = lambda x : max(x.iteritems(),key=operator.itemgetter(1))[0]\n",
      "test_weights = defaultdict(float)\n",
      "test_tags = ['N','V','V','N']\n",
      "for i in range(len(sent)):\n",
      "    for feat in wordFeatures(sent,test_tags[i],'X',i):\n",
      "        test_weights[feat] = 1\n",
      "    for feat in wordFeatures(sent,'X','X',i):\n",
      "        test_weights[feat] = 1\n",
      "\n",
      "def classifierTagger(words,featfunc,weights,all_tags):\n",
      "    \"\"\"\n",
      "    :param words: list of words\n",
      "    :param features: function from lists of words and tags to list of features\n",
      "    :param weights: defaultdict of weights\n",
      "    :param all_tags: list of permissible tags\n",
      "    :returns list of tags\n",
      "    \"\"\"\n",
      "    out = []\n",
      "    for i in range(0,len(words)):\n",
      "        best = defaultdict(float)\n",
      "        for cur in all_tags:\n",
      "       #     for prev in all_tags:\n",
      "                  for feat in  featfunc(words,cur,'X',i):\n",
      "                       best[cur] =    best[cur] +  weights[feat]\n",
      "       \n",
      "        out.append( argmax(best))\n",
      "                        #     print weights[featfunc(words,cur,prev,i).keys()[0] ]\n",
      "   \n",
      "    # your code\n",
      "    return out\n",
      "\n",
      "\n",
      "def evalTagger(tagger,outfilename,evalfile=devfile):\n",
      "    \"\"\"\n",
      "    :param tagger: a function that takes words and a list of candidate tags, and outputs a list of tags\n",
      "    :param outfilename: a filename to store the output\n",
      "    :param evalfile: a filename of the dev set data\n",
      "    \"\"\"\n",
      "    with open(outfilename,'w') as outfile:\n",
      "        for words,_ in conllSeqGenerator(evalfile):\n",
      "            pred_tags = tagger(words,alltags)\n",
      "            for tag in pred_tags:\n",
      "                print >>outfile, tag\n",
      "            print >>outfile, \"\"\n",
      "    return scorer.getConfusion(evalfile,outfilename) #run the scorer on the prediction file\n",
      "\n",
      "\n",
      "def oneItAvgPerceptron(inst_generator,featfunc,weights,wsum,tagset,Tinit=0):\n",
      "    \"\"\"\n",
      "    :param inst_generator: iterator over instances\n",
      "    :param featfunc: feature function on (words, tag_m, tag_m_1, m)\n",
      "    :param weights: default dict\n",
      "    :param wsum: weight sum, for averaging\n",
      "    :param tagset: set of permissible tags\n",
      "    :param Tinit: initial value of t, the counter over instances\n",
      "    :returns weights: a defaultdict of weights\n",
      "    :returns wsum: a defaultdict of weight sums, for averaging (as in pset 1b)\n",
      "    :returns tr_acc: training set accuracy\n",
      "    :return i: a counter of the number of instances seen\n",
      "    \"\"\"\n",
      "    tr_err = 0.0\n",
      "#    t=0\n",
      "    for i,(words,y_true) in enumerate(inst_generator):\n",
      "   #     pass # your code here\n",
      "    # note that i'm computing tr_acc for you, as long as you properly update tr_err\n",
      "        predicted_labels = classifierTagger(words,featfunc,weights,tagset);\n",
      "\n",
      "        \n",
      "        j=0\n",
      "    #    prev = start_tag\n",
      "        for word in words:\n",
      "            predicted_label = predicted_labels[j]\n",
      "            label = y_true[j]\n",
      "            if label != predicted_label:\n",
      "                tr_err = tr_err + 1\n",
      "            for feat in  featfunc(words,predicted_label,'X',j):\n",
      "                    weights[feat] =  weights[feat] - 1  \n",
      "                    wsum[feat] =  wsum[feat] - (Tinit + i)\n",
      "            for feat in  featfunc(words,label,'X',j):\n",
      "                    weights[feat] =  weights[feat] + 1 \n",
      "                    wsum[feat] =  wsum[feat] +  (Tinit +i)\n",
      "       #     prev= predicted_label \n",
      "            j=j+1\n",
      "  #  print tr_err      \n",
      "  #  print sum([len(s) for s,t in inst_generator])\n",
      "    return weights, wsum, 1.-tr_err / float(sum([len(s) for s,t in inst_generator])), i\n",
      "\n",
      "def trainAvgPerceptron(N_its,inst_generator,featfunc,tagset,output):\n",
      "    \"\"\"\n",
      "    :param N_its: number of iterations\n",
      "    :param inst_generator: generate words,tags pairs\n",
      "    :param featfunc: feature function\n",
      "    :param tagset: set of all possible tags\n",
      "    :returns average weights, training accuracy, dev accuracy\n",
      "    \"\"\"\n",
      "    tr_acc = [None]*N_its\n",
      "    dv_acc = [None]*N_its\n",
      "    T = 0.0\n",
      "    weights = defaultdict(float)\n",
      "    wsum = defaultdict(float)\n",
      "    for i in xrange(N_its):\n",
      "        # your code here\n",
      "        avg_weights = defaultdict(float)\n",
      "              \n",
      "        weights,wsum,tr_acc_i,j = oneItAvgPerceptron(inst_generator,featfunc,weights,wsum,tagset,T)\n",
      "        T = T + j + 1\n",
      "        for key in weights.keys():\n",
      "                 avg_weights[key] = weights[key] - ((wsum[key])/T)\n",
      "        \n",
      "        \n",
      "        confusion = evalTagger(lambda words, alltags: classifierTagger(words,featfunc,avg_weights,tagset),output)\n",
      "    #    confusion1 = evalTagger(lambda words, alltags: classifierTagger(words,featfunc,avg_weights,tagset),output,testfile)\n",
      "     #   if i==9:\n",
      "      #      print confusion\n",
      "        #    print confusion1\n",
      "        dv_acc[i] = scorer.accuracy(confusion)\n",
      "        tr_acc[i] = tr_acc_i\n",
      "        print i,'dev:',dv_acc[i],'train:',tr_acc[i]\n",
      "    return avg_weights, tr_acc, dv_acc\n",
      "\n",
      "import nltk\n",
      "#nltk.download()\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "from itertools import chain #hint, especially if you're obsessive about being pythonic\n",
      "stopset = set(stopwords.words('english'))\n",
      "lmtzr = WordNetLemmatizer()\n",
      "\n",
      "curr_suffixess = '--curr-suffess--'\n",
      "curr_suffixes = '--curr-suffes--'\n",
      "curr_prefix = '--curr-prefix--'\n",
      "prev_suffixes = '--prev-suffes--'\n",
      "curr_prefixes = '--curr-prefixes--'\n",
      "caps = '--caps--'\n",
      "thash = '--hash--'\n",
      "ing = '--ing--'\n",
      "dot = '--dot--'\n",
      "first = '--first--'\n",
      "stem = '--stem--'\n",
      "prev = '--prev--'\n",
      "\n",
      "def mywordFeatures(words,tag,prev_tag,m):\n",
      "    '''\n",
      "    :param words: a list of words\n",
      "    :type words: list\n",
      "    :param tag: a tag\n",
      "    :type tag: string\n",
      "    :type prev_tag: string\n",
      "    :type m: int\n",
      "    '''\n",
      " #   print offset,tag\n",
      "    out = {(offset,tag):1}\n",
      " #   out = {}\n",
      "    if m < len(words): #we can have m = M, for the transition to the end state\n",
      "  #     if words[m].isalpha():\n",
      "   #          out[(emit,tag,lmtzr.lemmatize(words[m].lower()))] =1\n",
      "    #   else:\n",
      "             out[(emit,tag,words[m].lower())]=1\n",
      "   #      out[(emit,tag, lmtzr.lemmatize(words[m].lower()))]=1\n",
      "       \n",
      "    return out\n",
      "\n",
      "def wordCharFeatures(words,tag,prev_tag,m):\n",
      "    output = mywordFeatures(words,tag,prev_tag,m) #start with the features from wordFeatures\n",
      "    # add your code here\n",
      "    output[(curr_suffix,tag,words[m][-1])] =1\n",
      "    \n",
      "  \n",
      "             \n",
      "    if(m>0):\n",
      "         output[(prev_suffix,tag,words[m-1][-1])] =1\n",
      "    return output\n",
      "\n",
      "def yourFeatures(words,tag,prev_tag,m):\n",
      "    output = wordCharFeatures(words,tag,prev_tag,m) #start with the features from wordFeatures\n",
      "  #  output[(prev,prev_tag)] =1  \n",
      "    if(m==0 or (m>0 and (words[m-1][-1] == '.' or words[m-1][-1] == ',') )):\n",
      "         output[(first,tag)] =1\n",
      "      \n",
      "    if words[m].isalpha():\n",
      "        output[(stem,tag,lmtzr.lemmatize(words[m].lower()))] =1\n",
      "    if len(words[m]) >1 :\n",
      "        output[(curr_suffixes,tag,words[m][-2] +words[m][-1])] =1\n",
      "    #    if words[m][-2:] == '..':\n",
      "     #         output[(dot,tag)] =1\n",
      "     \n",
      "        output[(curr_prefixes,tag,words[m][0] +words[m][1])] =1\n",
      "    if len(words[m]) >2 :\n",
      "        output[(curr_suffixess,tag,words[m][-3]+words[m][-2] +words[m][-1])] =1\n",
      "    if len(words[m]) >2 :\n",
      "        if words[m][-3:] == 'ing':\n",
      "              output[(ing,tag)] =1\n",
      "        if words[m][-3:] == '...':\n",
      "              output[(dot,tag)] =1\n",
      "            \n",
      "            \n",
      "#    if len(words[m-1]) >1 :    \n",
      " #          output[(prev_suffixes,tag,words[m-1][-2] +words[m-1][-1])] =1\n",
      "    #    output[(curr_suffixess,tag,words[m][-3]+words[m][-2] +words[m][-1])] =1\n",
      " #   if len(words[m]) >3:\n",
      "  #      output[(curr_suffixess,tag,words[m][-4]+words[m][-3]+words[m][-2] +words[m][-1])] =1\n",
      "     #   output[(curr_prefixes,tag,words[m][0] +words[m][1])] =1\n",
      "    output[(curr_prefix,tag,words[m][0])] =1\n",
      " #   if(m>0 and words[m][0]=='#' and words[m-1]!='.' ) :\n",
      "  #       output[(thash,tag,words[m])] =1\n",
      "    if(m>0 and words[m][0].isupper() and words[m-1]!='.' ) :\n",
      "         output[(caps,tag)] =1\n",
      "        \n",
      "#    if(m>0 and len(words[m-1])>1):\n",
      " #        output[(prev_suffixes,tag,words[m-1][-2] + words[m-1][-1])] =1\n",
      "    # your stuff\n",
      "    return output\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def clusterFeatures(words,tag,prev_tag,m):\n",
      "    output = yourFeatures(words,tag,prev_tag,m) #start with the features from yourfeatures\n",
      "    wrd = iidx_50.get(words[m])\n",
      "    if None != wrd:\n",
      "        cl = sizes[wrd]\n",
      "        output[(cluster,cl,tag)]=1\n",
      "    if m>1:\n",
      "        pwrd = iidx_50.get(words[m-1])\n",
      "        if None != pwrd and None != wrd:\n",
      "            cl = sizes[wrd]\n",
      "            pc1 = sizes[pwrd]\n",
      "            output[(cluster,pc1,cl,tag)]=1\n",
      "        if m <len(words) -1:\n",
      "            nwrd = iidx_50.get(words[m+1])\n",
      "            if None != nwrd and None != wrd:\n",
      "                cl = sizes[wrd]\n",
      "                nc1 = sizes[nwrd]\n",
      "                output[(cluster,nc1,cl,tag)]=1\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def train(value):\n",
      "    tr_all = []\n",
      "    for i,(words,tags) in enumerate(conllSeqGenerator(trainfile)):\n",
      "        if i==value:\n",
      "            break\n",
      "        tr_all.append((words,tags))\n",
      "    return tr_all\n",
      "\n",
      "alltags = set()\n",
      "for i,(words, tags) in enumerate(tr_all):    \n",
      "    for tag in tags:\n",
      "        alltags.add(tag)\n",
      "        \n",
      "\n",
      "def makePlots(tr_acc,dv_acc):\n",
      "    ax1 = plt.subplot(1,2,1,xlabel='iteration',ylabel='accuracy')\n",
      "    plt.plot(tr_acc,'rx-')\n",
      "    plt.title('training')\n",
      "    plt.subplot(1,2,2,xlabel='iterator',sharey=ax1)\n",
      "    plt.plot(dv_acc,'bx-')\n",
      "    plt.title('development')\n",
      "    \n",
      "print 'Train ---50'\n",
      "tr_all = train(50)\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,yourFeatures,alltags,'perc')\n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'With Cluster'\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,clusterFeatures,alltags,'perc')\n",
      "# this code makes plots of the training and development set accuracy\n",
      "makePlots(tr_acc,dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train ---50\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.563756997719 train: 0.418897637795\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.608127721335 train: 0.785826771654\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.617872693344 train: 0.925984251969\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.622226829774 train: 0.954330708661\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.622434169604 train: 0.949606299213\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.624300228074 train: 0.948031496063\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.626788306034 train: 0.965354330709\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.627202985694 train: 0.979527559055\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.628654364503 train: 0.976377952756\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.629483723823 train: 0.982677165354\n",
        "With Cluster"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.588015757827 train: 0.442519685039\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.635703918723 train: 0.837795275591\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.645448890732 train: 0.929133858268\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.649595687332 train: 0.954330708661\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.650217706821 train: 0.973228346457\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.651254405971 train: 0.976377952756\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.651669085631 train: 0.982677165354\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.652913124611 train: 0.987401574803\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.655193862741 train: 0.988976377953\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.652498444951 train: 0.990551181102\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEVCAYAAAAIK+VbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XdYVMfaAPB3aUqT3qsCUhWwgA1dowa8lmCLaOxGiYnR\n3FxvNIleMTFGk3g/NSQRjUo0ttgLikZlFSsawYYoKGVBRaRXl92d74/JuS7IypYD297f85wHdvec\n2Vl4993ZOTNzOIQQQAghpFv0VF0BhBBC7Q+TP0II6SBM/gghpIMw+SOEkA7C5I8QQjoIkz9CCOkg\nTP4aaN68eb+sXLlyKdv7IiRpxowZicuWLfu6rcpPTEycERERkdpW5aM3M1B1BXSRp6dn3tatW2e9\n9dZb5xQ5/pdffpnXFvsiJInD4RAOh4MTgSQkJibO2LJly+zU1NQIVddFWdjyVwEOh0MIIZyWHhMK\nhfiBjNSGtDhFmg+TfzubOnXqjoKCAvdRo0YdMzc3r/7+++//raenJ966dessDw+P/KFDh54BAJgw\nYcI+Jyenp5aWlhWDBg06n5mZGcCUIfl1nMfjcV1dXQv/+9//furg4FDs7Oz8JDExcYYi+5aWltqM\nGjXqmIWFRWVYWFja0qVLV+LXct2Rnp4e2qNHj5udOnWqiomJ2dPQ0NCReez48eMjQ0JCMqysrMr7\n9+9/6c6dO90AANasWbN4woQJ+yTLWbhw4fqFCxeuBwCorKy0mD179hZnZ+cnrq6uhcuWLftaLBa3\nmHcuX77cr3fv3tctLS0rwsLC0q5cudKXeYzL5fI+//zzb8PDw69ZWFhURkdHHy4vL7cCAMjLy/PU\n09MTJyYmznB3dy+wsbEp3bhx4wfXr1/v3b1799tWVlblH3/88Y+Sz7V169ZZAQEBmdbW1mVRUVHJ\nBQUF7sxjenp64oSEhNiuXbs+tLKyKp8/f348AMD9+/f9582b98uVK1f6mpubV1tbW5cp/1dXIUII\nbu28eXp65p49e/YtQgjk5eV5cDgc8fTp0xPr6uqMGxoaOhBCYNu2bTNqampMBQKB4SeffPJ/ISEh\n6czxM2bM2LZs2bKvCCGQkpLCNTAwaFy+fHmcUCjUP3HixHATE5PaiooKC3n3nThx4p5Jkybtqq+v\n75iZmenv5uZWEBERcUHVfy/c2n57+fKlkbu7e/66desWCoVC/f37948zNDQULFu27KubN2+G2tvb\nF6elpfUWi8Wc3377bZqnp2euQCAwzMvL8zAxMamtrq42I4SAUCjUd3JyenLt2rUwQghER0cf+uCD\nD36pq6szfv78uV1YWNi1hISEuYTQGB8wYEAqIQRKS0utLS0ty3///ff3RCKR3u7du2OsrKzKysrK\nrAghMGjQIJ6Li0vhvXv3Ampra03GjRu3f8qUKTsIIZCbm+vJ4XDE8+bN+/nly5dGp0+fHmZkZPQy\nOjr6UElJiW1RUZGzvb198fnz5wcSQuDw4cPveHt7Z2dlZfmKRCK9lStXftmvX79LzN+Cw+GIR40a\ndbSysrJTQUGBm52d3fPk5ORIQggkJiZOZ+qs6ZvKK6CLm2TyZwI3NzfXU9r+5eXllhwOR1xVVWVO\nCE3oS5cu/ZoQmtCNjY3rRCKRHrO/vb19MfPmk3VfoVCob2hoKHj48KEP89jSpUu/1pZAx+3N2/nz\n5wc6OzsXSd7Xr1+/S0uXLv163rx5PzMNCGbz9fXNunDhQgQhBAYMGJC6ffv2qYQQOH369DAvL68c\nQgg8e/bMoUOHDg319fUdmeN27do1afDgwecIaZr8t2/fPjU8PPyq5HP07dv3cmJi4nRCCHC53JTP\nP/98FfNYZmamv5GR0UuxWMxh3kNPnjxxYh63sbF58ccff0xgbo8bN27/+vXrFxBCICoq6uSWLVtm\nMY+JRCI9ExOT2oKCAjdCaPK/dOlSP+bxd999d+/q1asXN6+zpm/Y7aMm3Nzc+MzvYrFYb8mSJau9\nvb1zLCwsKjt37pwLAPDixQvblo61sbEp1dPTEzO3TUxM6mpqaszk2bekpMROKBQaSNbD1dW1kI3X\nhtTfkydPnF1cXIok7/Pw8MgHAMjPz/dYu3btv6ysrMqZrbCw0PXJkyfOAACTJ0/etXv37kkAALt2\n7Zr83nvv7WSOa2xsNHRycnrKHPfBBx9sLCkpsWvp+d3d3QuaPz/zHABN3yPu7u4FjY2NhpLvCQcH\nh2Lmd2Nj4/rmt5n3RH5+vsfChQvXM3WysbEpBQAoKipyYfZ3dHR8xvxuYmJSV1tbayr7X1MzYPJX\ngZZGUEjet3PnzveOHj06+uzZs0MqKystcnNzOwM0PfkmzygMWfa1s7MrMTAwEPL5fDfmPsnfkXZz\ncnJ6Kpn8AGiSBKBJ98svv/ymvLzcitlqamrMJk6cuBcAYPz48ft5PB63qKjI5fDhw9GTJ0/exRzX\noUOHl6WlpTbMcZWVlRbM+QJJLi4uRczzST6/5AeSZL98QUGBu6GhYaOtre0LeV+ru7t7waZNm+ZK\nvp7a2lrTPn36XG3tWG0a/YTJXwUcHByKHz165CXt8ZqaGrMOHTq8tLa2LqutrTX94osvVkk+Tgjh\nEBlHYci6r76+vmjs2LEH4+Li4urr642zsrL8duzYMVWbgh1J169fv8sGBgbCDRs2LGhsbDQ8ePDg\n2OvXr/fmcDhkzpw5mzdu3PhBWlpaGCGEU1tba5qUlDSCaUnb2dmVcLlc3owZMxK7dOny2NfX9wEA\n/UB5++23T3/66af/ra6uNheLxXqPHj3yunDhwsDmzz98+PCTDx8+7Lp79+5JQqHQYO/evROzsrL8\nRo4ceRyAxvHvv/8+5f79+/51dXUm//nPf76aMGHCPnnik3kffPDBBxtXrVr1BTOIorKy0mLfvn0T\n3nQcc6yDg0NxYWGha2Njo6E8f191hMlfBT7//PNvV65cudTa2rrswIED45oH8LRp07Z7eHjku7i4\nFAUFBd3t27fvFcl9mo+/ftMbQJ594+Pj51dWVlo4Ojo+mz59+m+TJk3abWRkJFD8lSJNYWho2Hjw\n4MGxiYmJM2xsbEr/+OOPd8eNG3cAAKBnz55/bd68ec78+fPjra2ty3x8fLK3b98+TfL4yZMn7zp7\n9uwQptXP2L59+zSBQGDEjKyZMGHCvmfPnjkCNI1NGxub0uPHj49cu3btv2xtbV/88MMPi44fPz6S\nGVHD4XDI1KlTd8yYMSPRycnpqUAgMNqwYcMC5nlk+RBg9omOjj68ePHiNTExMXssLCwqu3XrdufU\nqVOR0sqSrOeQIUPOBgYG3nN0dHxmb2//XL6/snrhEIINO9SyxYsXr3n+/Ln9tm3bZqq6Lki3DR48\nOGXq1Kk7Zs2atVXVddEWrLf8Z82atdXBwaG4W7dud6Tts2DBgg0+Pj7ZwcHBt9LT00PZrgNSzIMH\nD3xv377dnRDCSUtLC9u6deusMWPGHFJ1vdQFxrZqydrViWTDevKfOXPmtuTk5Chpj584ceIfOTk5\n3tnZ2T6bNm2aO2/evF/YrgNSTHV1tfm4ceMOmJmZ1cTExOxZtGjRD6NHjz6q6nqpC4xt1cLzT+xi\nfSmBiIiI1Ly8PE9pjx89enT09OnTfwMACA8Pv1ZRUWFZXFzsIDksC6lGr169bmRnZ/uouh7qCmNb\ndVJSUgarug7apt3XkSkqKnJpPpa8sLDQtfkbBD/lUVtjuxsBYxupC1liWyWjfZpXTNqbQdkZbMuX\nL8cyWCxD4eOPHwdSXt60jPJyen97llFeDuTDD4GUl+t8bKtDPGEZbVOGrNo9+bu4uBRJTh4qLCx0\nbT6zEGmZ/v0BvvwSoKKC3q6ooLf792/fMiwtAb75hh7XBjC2kSZp9+Q/evToo8wY4atXr/axtLSs\nwD5RNZaU9CrhMioq6P2ykky6TNL+5ht6P9tlNDYCVFUBFBcD5OcDZGUBpKcDXL5M9z91CiAwUPbn\nlQPGNtIkrPf5T5o0aff58+cHvXjxwtbNzY2/YsWK5cxsuNjY2IR//OMfJ06cOPEPb2/vHFNT09q2\nHEPO5XKxDGXLYFrc33xDj5dMvLJKSqLlLFwIXF9fgEOHAFJTAf76C6BbN4D6+qZbQ8Pr9zFbWRlw\nr14F8PcHCA9/fV8AAGNjunXs+Op3Y2MAQ0OAhAQAfX35/w6gXbGt0TGJZbBCbSd5/X3BE1VXQ/Mx\niVeyhVxRAXDpEsCIEbKVwST8f/8b4PvvX29xi8UAL14AFBUBPHny+s+CAoDsbNoqd3CgPw0MAIKC\nAMzNmyZoyU0yed+/D+DjA3DkCMC0aQB79wLMnUvLHjGiaYJ/0+tYtAgAADhbtgBR0bhxjG3Uljgc\njkyxjclf2zXvIlGk26W6mrbUR4wAWLIEoK6uaYJ/9owmcRcXAGdn+lPyd3NzgE2baDJftgxg5Upa\n7g8/yF6H/HyAkSMBjh8H8PB4/bYsjh8H8PUFuHMHOOPGYfJHWgmTvzZgo9XOHPOmljshAKWlADk5\nAI8evf6zupq2qnv1on3p774L4O39Krk7OdHE3trrqKgA6NwZYOdO+g3g8WOAceMALCxa74pJSqLf\nFL777tXr+OwzgLt3m/4txGL6gSTttejrAxgZAef5c0z+SCth8tcGbLTaAWhyz8oCCAgA2LMHoLa2\naVLMyQHQ06MJ3cur6U9bW4D4eOXq8PQpfd516+iHjLk5gKMjPTFbXk5/mpsDWFvTzcqq5d+trWkf\nf0wMwNmzAALB68k9N5fu1/x1eHnR1/L3hx/HygqTP9JKmPy1hWSr/bvvaJ+1WAxQVka38vKWf5e8\nXVpKj7GxoUmey6UfBExi9PamCbMlcXEAM2c27VrJzwfYto0+Jk1WFsDhw3TLygKwtwf44gva0heJ\nmn6AiEQAlZWtv57nzwEyMgBMTQFKSgBCQwH8/Jom+S5dAExMWq6TxDcpWd8gbQFjG7UlTP7a4ulT\nmvTXraOJu1Onpi1haa1k5nd9fXrsmjWKtdxl/fYhFgNcu0aT/ZEjADU1ANHRdKutBRg0iJ2Tzsp+\nC/obJn+krWSObWVnk7XVRqumo8RiQng8QiZMIMTCgpDAQEJOnCBk3jxCysvlK+v48dePKS+n98uq\nvJyQDz8kJDeX/mTKa2ig9Zo7lxBHR1rPL78k5Pp1+hrYxMbrkPB3fGFsI60ja2xjy1+dVFUB7NgB\n8PPPtJ9+5kyAhw9pPzULrV2l5OXRk7W3btGTrIcPA5w+TcfpR0cDvPMO7XbRENjyR9oKu300yd27\nAL/8ArB7N8CQIQAffUS7SU6cYGe0j7JevACYMYN27Zw5A/DWWwATJgCMGkX78jUQJn+krWSNbbyM\nY1uJi6MnRiXl5786SSoQAPzxB03yb78NYGcHcOcOwL599IQsh0MTfPMWvqVl+yX+hw8B/vlPerL3\n2TPaus/JoSdXx43T2MSPEMKWf9uRNilp82aAkyfpT19f2sp/552WZ6ayNc5fHtXV9ANo61aa6Pv3\npyON+vRpvzq0A2z5I22FLX9V8/CgiX/kSDo7lssFcHMD+Mc/6NDLM2cAUlIAxo+XviQBGytZyrIw\nGyG0jjNnAri7Axw9ShM+nw9w4EDTxA/Qvt8+EEJtAlv+bYkQgAUL6CQpAwM6Bj00FMDT8/WlEBwd\nW/4QaG12bmveNESypgZg+3Y6Zt/ICGDWLIApU+jsWy2HLX+krfCEr6pdvEhPij57RpdDuHkT4D//\noROaWloA7flzOgmrpfVxDAzoCdcLF+jiZpKLmHFkyF+SHyCrV9PVMP/4g47Lf/ddmvR795atLC2B\nyR9pK0z+qlJYCDB1KsD58zRBX7gA0LNn6wuRiUR03ZzmHwy5ubRLxtiY3u7YkZ4srq+nxzRftlja\nyphCIU34VlYAPXrQLp4xY6TPhtVymPyRtsLk396qqwE+/5yuXmlhARAZSbtW5F0WQVJrs1qFwjev\nfc9spaV0bZ2hQwEePADYsKH95wmoGUz+SFth8m8vQiFN+EuWALx8CfDppwBfffXmdeVlxeZa/Cwt\ni6AtMPkjbYXJv60RQidhzZ9PFxnr3p0uVdy5s6pr1pQqhotqAEz+SFth8ldGawkzPR3gk08Abt+m\ni639/DM9capDJ0w1HSZ/pK1wnL8yamro0smS4+sXLaJ99tOn0+UNMjLouvKPHwNMnIiJHyGkUbDl\n3xKJa73C0qUAy5fTZJ+fT5dJNjEB2LKFDplEGglb/khbYctfGZaW9PqyL1/SPvy9e+n9HA7Ahx/S\nbh9M/AghDWag6gqoNaGQ/tTXpzNwjx6V/WLhCCGkxjD5t4Tp9snJod8CAgPpujwWFqquGUIIsQK7\nfVpy6hRAYyM9mUsIwKFDr+5HCCEtgMm/JWZmdBE2d3e6BIKdHT0HYGam6pohhBArcLRPS2prafJ3\ndQVYsYKuyYO0Co72QdoKR/so4+ef6Wiex48Bhg1TdW0QQoh1eMK3udpagLVrAebMod08HTqoukYI\nIcS6Nmn5JycnR/n5+WX5+Phkr1mzZnHzx8vLy63GjBlzKDg4+FZ4ePi1e/fuBbZFPRTyyy8AAwYA\nXL1Kr1OLkASNjm2EJBFCWN2EQqG+l5dXTm5urqdAIDAMDg7OyMzM9JfcZ9GiRd9/9dVXywghkJWV\n5TtkyJAzzcuhVWtntbWEODgQcv48IZ06EVJT0/51QO3i7/jSndhGOkPW2Ga95Z+Wlhbm7e2d4+np\nmWdoaNgYExOz58iRI+9I7nP//n3/wYMHpwAA+Pr6PsjLy/MsKSmxY7suctu4kS7o9ugRXfve1FTV\nNUJqRKNjG6FmWO/zLyoqcnFzc+Mzt11dXQuvXbvWZC2E4ODgWwcPHhw7YMCAi2lpaWH5+fkehYWF\nrnZ2diWS+8VJXPSEy+UCl8tlu7qv1NXRa+QmJ9P17t97r+2eC7U7Ho8HPB5PqTI0NraRVlM0tllP\n/hwOp9UxbEuWLFm9cOHC9aGhoendunW7Exoamq6vry9qvl+crFe8YkNCAkDfvnQtn9RUgF272u+5\nUZtrnmBXrFghdxkaG9tIqyka26wnfxcXlyI+n+/G3Obz+W6urq6FkvuYm5tXb926dRZzu3Pnzrld\nunR5zHZdZFZXB/DddwAnT9Jr7A4cCNCpk8qqg9STRsY2QlKw3uffq1evG9nZ2T55eXmeAoHAaO/e\nvRNHjx59VHKfyspKC4FAYAQAsHnz5jmDBg06b2ZmVsN2XWS2aRNAnz4AISEA+/fjKB/UIo2MbYSk\nYL3lb2BgIIyPj58fGRl5SiQS6c+ePXuLv7///YSEhFgAgNjY2ITMzMyAGTNmJHI4HBIUFHR3y5Yt\ns9muh8zq62mrPymJjvE/exbg119VVh2kvjQuthF6A1zeYf16gHPnAI4coa3+TZsATp9u++dFKoXL\nOyBtJWts6/YMX6bVf+wYvX3gAHb5IIR0gm6v7bN5M0DPngA9egA0NNATvtHRqq4VQgi1Od1t+Tc0\nAKxZQ6/OBQDw558AwcEADg6qrRdCCLUD3W35//orbfH37ElvY5cPQkiH6OYJ34YGAG9vgMOHAXr1\nolftcnQEuHWLruGPtB6e8EXaCtfzf5MtW+iY/l696O2UFAAfH0z8CCGdoXt9/i9fAnz77avr8gJg\nlw9CSOfoXvLfsoWe2O3dm94WiWj3z5Urqq0XQgi1I91K/kyr/8CBV/ddvAjg7Eyv2YsQQjpCt/r8\nt24FCAoCCAt7dR92+SCEdJDujPZ5+ZKe1P3jD7qIGwCAWAzg7k7H+Pv7s/dcSO3haB+krXC0T3Pb\ntgEEBLxK/AAAaWl06WZM/AghHaMbff4CAe3r37On6f3Y5YMQ0lG6kfwTEwH8/OiVuhiE0OR/8KDK\nqoUQQqqifd0+SUkAFRWvbgsEAF9/DTBsWNP9MjIAOBw67BMhhHSM9iX//v3pBdiZD4BffqE/33+/\n6X5Mlw9HJef8EEJIpbRztE9FBf0AWLiQLty2bx9AVFTTffz9aXdQeLjSdUWaB0f7IG0la2xrZ/IH\nAMjLA+jcmX4TuHix6WOZmQCRkQD5+QB62vflB7UOkz/SVro91LOiAuD77wHGjwcwMGh6DgCAdvmM\nHYuJHyGks7Qv+zFdPt98Q3//+OOm5wAAcIgnQkjnaV/yv3SJJn5LS4CCAtq3/8039H4AgEePAJ49\no91BCCGko7S3z58QAFNTgOJiAHPzV/d/9x3A48cAGzcqX0mksbDPH2kr3e7zBwAoLQXo0KFp4gfA\nLh+EEAJtTv58Pl20rfl9jx4BcLkqqRJCCKkL7U3+BQUAbm5N7zt4EGDUKABDQ9XUCSGE1IT2Jn8+\n//Xkj10+CCEEANqe/CW7fZ49A7hz5/U1fhBCSAdpb/Jv3u1z+DDA8OH0JDBCCOm4Nkn+ycnJUX5+\nflk+Pj7Za9asWdz88RcvXthGRUUlh4SEZAQFBd1NTEycwXolmrf8scsHsUAtYhshNhBCWN2EQqG+\nl5dXTm5urqdAIDAMDg7OyMzM9JfcZ/ny5XFLliz5lhACJSUlttbW1qWNjY0GkvvQqinBzY2Qx4/p\n7y9eENKpEyG1tcqVibTG3/GlmbGN0BvIGtust/zT0tLCvL29czw9PfMMDQ0bY2Ji9hw5cuQdyX2c\nnJyeVlVVdQIAqKqq6mRjY1NqYGAgZK0SQiHt43dxobePHKF9/SYmrD0F0j1qEdsIsYT1K3kVFRW5\nuLm58Znbrq6uhdeuXWuybvKcOXM2v/XWW+ecnZ2fVFdXm//xxx/vtlRWXFzc/37ncrnAlXV8/tOn\nALa2AEZG9PaBAwBTpsj5SpA24fF4wOPxlCpDLWIboWYUjW3Wkz+Hw2l13vqqVau+CAkJyeDxeNxH\njx55DRs27M9bt24Fm5ubV0vuJ/kGkYtkf39lJUBqKsDu3YqVhbRC8wS7YsUKuctQi9hGqBlFY5v1\nbh8XF5ciPp//v2E2fD7fzdXVtVByn8uXL/ebMGHCPgAALy+vR507d8598OCBLysVSEoCuH//1Uif\n48cB+vWjHwAIKUHlsY0Qi1hP/r169bqRnZ3tk5eX5ykQCIz27t07cfTo0Ucl9/Hz88s6c+bMUACA\n4uJihwcPHvh26dLlMSsV6N8fYMsWAHt7env3boDGRlzFEylN5bGNEJtkOSss73bixInhXbt2feDl\n5ZWzatWqzwkhsHHjxtiNGzfGkr9HQYwcOfJY9+7dbwUFBd3ZuXPn5OZlgDIjIubOJaR/f0Lu3SPE\n0PDVqB+E/gYKjPYh6hDbCLVC1tjWziWdo6PpZRo//BBgwADs8kGvwSWdkbbS7SWd8/IAzp0DmDqV\nruvf/DKOCCGk47Qv+VdUADx4ALByJV3T/6OPXr+MI0II6TjtS/7nztHWvo8PQH4+QGBg08s4IoQQ\n0sI+/4cP6QJuOTn0Kl5FRQAWFuxXEGk07PNH2kp3+/yZCV6lpXSGLyZ+hBB6jfYlf2Yp5/x8AE9P\nVdcGIYTUkvYlf+YKXnl5AB4eqq4NQgipJe1M/u7uNPljyx8hhFqkfcmf6fbB5I8QQlJpX/JnWv75\n+djtgxBCUmhX8icEW/4IISQDqcl/7NixB5OSkkaIxWLN+YCoqADQ1wfo1AmTP0IIvYHUxD5v3rxf\ndu7c+Z63t3fOkiVLVmvEmuRMq7+iAkBPD8DSUtU1QgghtSQ1+Q8bNuzPXbt2Tb5582YPT0/PvCFD\nhpzt16/f5W3bts1sbGw0bM9KykxypA/29yOEkFRv7NIpLS21SUxMnPHrr7++36NHj5sLFizY8Ndf\nf/UcNmzYn+1VQblgfz9CCMlE6jV8x4wZcygrK8tv6tSpO44dOzbKycnpKQBATEzMnp49e/7VflWU\ng+QEL0z+CCEkldSF3VJSUgYPHjw4pZ3r8z8KLX41ZQrA228D3LxJu38+/bRtKoc0Hi7shrSV0gu7\n3bt3L7C8vNyKuV1eXm71888/f8hWBdsEdvsghJBMpCb/zZs3z7GysipnbltZWZVv2rRpbvtUS0G4\ntANCCMlEavIXi8V6kmP8RSKRvtqO8gEAEIno2v2urriiJ0IItULqCd/IyMhTMTExe2JjYxMIIZyE\nhITYqKio5PasnFyKiwGsrQHq6wGEQgArq9aPQQghHSX1hK9IJNLftGnT3LNnzw4BoOP+33///V/1\n9fVF7VIxeU+KXb0K8PHHAL/+Sk/83rnTdpVDGg9P+CJtJWtsa89lHPftA9i9G2D6dPoBcOxY21UO\naTxM/khbyRrbUrt9Hj582PWLL75YlZmZGVBfX2/8d6Hk8ePHXdisKGsKCnA1T4QQkpHUE74zZ87c\n9sEHH2w0MDAQpqSkDJ4+ffpv77333s72rJxccIIXQgjJTGryr6+vNx46dOgZQgjH09MzLy4uLi4p\nKWlEe1ZOLjjMEyGEZCa126djx44NIpFI39vbOyc+Pn6+s7Pzk9raWtP2rJxc8MLtCCEkM6knfK9f\nv97bz88vq6KiwnLZsmVfV1VVdfrss8++69Onz9V2qZi8J8UcHemyDt26AWRlAdjZtV3lkMbDE75I\nWym1vINIJNLfu3fvRHNz82o3Nzd+YmLijIMHD46VNfEnJydH+fn5Zfn4+GSvWbNmcfPHf/jhh0Wh\noaHpoaGh6d26dbtjYGAgrKioUHzx/ZcvAcrKAIyNARoaAGxtFS4KoTdp99hGqK0QQlrcwsPDr4rF\nYo60x6VtQqFQ38vLKyc3N9dTIBAYBgcHZ2RmZvpL2//YsWMjhwwZcqb5/bRqMsrJIcTTk5DbtwkJ\nCJD9OKSz/o4v9Y9thOQka2xL7fMPCQnJeOedd45MmDBhn4mJSR0A/bo6duzYg2/6MElLSwvz9vbO\n8fT0zAOgS0AfOXLkHX9///st7b9r167JkyZN2q3QJxdDsr8fh3miNqKS2EaojUhN/g0NDR2tra3L\nzp0795bk/a0l/6KiIhc3Nzc+c9vV1bXw2rVr4S3tW1dXZ3Lq1KlIaauFxsXF/e93LpcLXC635SfF\nYZ6oFTweD3g8nlJlqCS2EWqForEtNfknJibOUKQiHA5H5jNZx44dGzVgwICLlpaWFS09LvkGeSNm\nghcmfySsIoxFAAAgAElEQVRF8wS7YsUKuctQSWwj1ApFY1tq8p85c+Y2ydtM4G/dunXWmwp0cXEp\n4vP5bsxtPp/v5urqWtjSvnv27Ilh5Wsxnw8QHAyQkgIQFqZ0cQi1RCWxjVAbkZr8R4wYkcQk/Pr6\neuNDhw6NcXZ2ftJagb169bqRnZ3tk5eX5+ns7Pxk7969E3fv3j2p+X6VlZUWFy5cGLhr167Jyr0E\noMl/1Ci8cDtqUyqJbYTaiNTkP378+P2StydPnryrf//+l1ot0MBAGB8fPz8yMvKUSCTSnz179hZ/\nf//7CQkJsQAAsbGxCQAAhw8fjo6MjDxlbGxcr+yLwCt4ofagkthGqI3IvKpnVlaW38iRI4/n5OR4\nt3GdAEDOiTAWFgD37gF07QpQWwvAUcncHaRBcJIX0lZKr+ppZmZWw3T7cDgc4uDgUNzSpBaVq6yk\nV/GqrKQnfTHxI4RQq6Qm/5qaGrP2rIjCmAXdcE0fhBCSmdRVPQ8dOjRGclp6RUWF5eHDh6Pbp1py\nwP5+hBCSm9TkHxcXFyc5RtnS0rIiTh0HJzMTvLDljxBCMpOa/Fs6YSASifTbtjoKkJzghcM8EUJI\nJlKTf8+ePf/69NNP//vo0SOvnJwc73/+85//17Nnz7/as3IywaUdEEJIblKT/48//vixoaFh48SJ\nE/fGxMTs6dixY8NPP/30UXtWTiZ4BS+EEJKbzOP825vMY6G9vAAOHaLLOtTVAehJ/TxD6H9wnD/S\nVkpdzAUAYOjQoWckR/uUlZVZR0ZGnmKrgqwQiwGKiuhPd3dM/AghjZOUBFDRbPm/igp6f1uSmi1f\nvHhhKznax9rauqy4uNihbasjp+fPAczNAZ49wy4fhHQIGwlTXcro3x/gyy9flVNRQW/3769cPVoj\nNfnr6+uL8vPz/zd8Ji8vz1NPT08sX/FtDE/2ItSutClhqksZlpYA33xDj8vLoz+/+Yber2g9ZCG1\nzz85OTlq7ty5mwYNGnSeEMK5cOHCwE2bNs2NiopKlr14xcnUL3rgAMCOHQD+/gBmZvTVIyQDXezz\nT0qiSUIyqVRUAFy6BDBihGxlMMmNSU7Nb7dXGZLl/PvfAN9/L//x7VGGUAhQUwNQXf361vz+oiKA\nxESAiRMBXF1pGRYWr7bmtzt1AjAweL0eP/8sW2y/8YTv8+fP7Tdt2jQ3JCQko6GhoaO9vf3zgQMH\nXpDvT6MYmd4g69YBPHoE8OIFwMiRAO+91x5VQ1pAF5O/JiddQugSXgJB0+3xY4BBgwCSkwEcHenp\nP7GY7sv83vx289+fPQOYOxfgxx9pUn35Uv6tshLg6lXaDn358lVCFwhou9TcvOnW/D4DA4ALF2ga\nS04GGDyYHltZ+WqrqGh6u6oKwMSk6QeCkRHA+fNKJv/NmzfP2bBhwwI+n+8WGhqafvXq1T59+/a9\n0vyyjm1FpjfIp58CODkBHDwI8MMP8n3XQjpNF5M/gOKJWyCgp9iKi2myvHcPYPFigNmzaQISiWgr\nV56fNTUAN24AdO9O12MUCAAaG19P8Mymr0+TG7MZGNAybG3p63Jyovfr6dFNX//V781vM7+LRAAP\nH9IFgR89AujRgybjDh1k3xobAX7/HWDqVIB9++jfxcWFJngTk9bXmlT0Q1kspq+f+TAoLASIjwdI\nSlIy+QcFBd29fv167759+17JyMgIycrK8vv888+/PXTo0JjWCmWDTG+QCRMAxo2jHwJpafS7EkIy\n0NXkD0D7lTt3pknPxORVQi8ubvq75H1VVQB2drR1bW1NE83gwQC3b9PrKJmb04RqYEB/Sv7e0s/6\neoBt2+iX9T17ABYsALCxaZrcmc3QkG76EusLqEv3ExtlsN0dZ2UlY2wTQlrcevbseYMQAsHBwRn1\n9fUdCSHg7++fKW1/tjdatVaEhxOSkkKIkREhQmHr+yP0t7/jq11iufkmU2y34PhxQsrLm95XXk7v\nb41QSMjdu4T8+CMhAQGE+PsToqdHiL09ISEhhERGEjJtGiGffUbI2rWE7NxJyJkzhNy5Q0hJCSEi\n0avn+/DDV/VoflsWbJShzN9C3cpgg2Q9ZI1tqQ9ER0cfKisrs1q+fHncgAEDUkeNGnV0+PDhJ2Qp\nlI1NpjeIkxMhPB4hXl6K/L2QDtPE5C9P0nzyhJBDhwhZsoSQwYMJ6dSJkM6dCenalZBvvyXk6lVC\nnj3T3KSLpJM1tmWa4cvj8bhVVVWdoqKiko2MjASyfRFRTqtfjZkzKUeOAKxdC3DmTHtUC2kJTe32\naanP3tAQ4OZNgGvXXm21tXTSe3g43cLC6AlJZbsXkHqS7DqSNbY1d3mH3Fx6mn/ZMhrVW7a0X+WQ\nxtPU5A9AQ79LF4BJkwAyMwGyswGCgpomem9vvKhda9joa1eXMhTp89fc9RBwghfSQRUVADExdEkr\nPp8Ocisro639DRvoCVQfH+1P/DhRrCnJiWIyk6VvSBUbtNYvumMHITExhEyeTMj27bJ2hyFECNHc\nPv/+/Qnp0oWQp08VO1GqLHXp82fjpLHkcbm5iv8t1aEMkYiQhgZC7t1juc9fFVr9avzttwDl5QCX\nLwOsWgUwcGD7VQ5pPE3s9vn4Y3qK6+JFuo4hQPv32avL8EjJcpSZbAbwqhvt5k06WlyWiWHNfy8s\nBIiOBti7F8DKCqChoelWX//6fc0fKy8HOH8eIDSUDodtbKSbUNj674S8mu0rFGp7n/+8eQCBgQCr\nV9MPAObdgJAMNC3579xJJw/xeLQ/XxFs9C0zx6h6WQVCaMLMyqITs/78k841qKqSb2NmzRoZ0XJN\nTWkSfdPEsOa/i8V0ToSzM50T0bUrXXqhY8eWN2Pj1+8TiQD++IOex9m/H+DDD+l8CkNDWh9mroO0\n36uqAJYula/PX3OT/8iRADNm0E7O2tqmi1wg1ApNSv6HDtG2ztmztL2jKDZa3EIhQEkJwF9/0cld\na9fSJEUITYKENN1auo+5v7QUYOVKgCVL6EzZujr6VpblZ10dfctzOK9a2p0707p06iR9Y9bE6dSJ\nvp4NG2gngr299kwU0/7RPsHBAF9/DfDJJ3SBD4TkoCnJPzkZYNo0+rNHD+WfW1qLu7YW4OlT2oJ9\n08/SUro/IfSD6NkzWq+OHWkibr7p6bV8n0AAcOUKQK9etLvl7bdp4jY1pbOO3/TT1JSun7N8uepn\n1qpLGZJkjm1ZTgyoYoPWTopZWhJy4AAhXO6b90OoBaABJ3x5PEJsbQm5dIneVvZEqVhMTyj++CNt\nf/fpQ4iPDyFmZoR07EgngfXtS8jYsfSk49dfE7J5My3/xg1CiooIef5ce2b4aitZY1szW/7V1QAO\nDvQ726VLdJEQhOSg7i3/tDTas7l7N8CQIfQ+ebsHKioArl+nw0DT0uhPANpyHj+e9pcvXQrg60u7\nQWQZHqqOLV3UlHZ3+2RmAowZA/Duu7Tjb/ny9q0c0njqnPxv3aLdIFu20A8ASdK6bRobAe7caTrL\nl8+nXTLM5C9fX4CNG5UfZYPUm3Yn/1OnaOQ7OwO89RY98YuQHNQ1+Wdl0ZBet462bVrCrMr544/0\ndNe1awAZGXSuI5Pow8PprF/JcRDY4tYNSl/AXRnJyclRfn5+WT4+Ptlr1qxZ3NI+PB6PGxoamh4U\nFHSXy+Xy5HqCggI6tBNn96J21NZxnZsLMGwYnbYiLfFXVAB89BEdtfLf/9Llrb76ip6MvXcPYOtW\ngNhYgJCQ1wfAjRjxegvf0hITv86S5cSAPJtQKNT38vLKyc3N9RQIBIbBwcEZmZmZ/pL7lJeXWwYE\nBNzj8/muhBAoKSmxbV4OvOmk2LJlhPznP4S4udEzWAjJCeQ84ctWXBMpsV1YSGfuxsdLr3N5OV16\n2daWkOvXVTPDF6k/WWOb9cHxaWlpYd7e3jmenp55AAAxMTF7jhw58o6/v/99Zp9du3ZNHjdu3AFX\nV9dCAABbW9sXLZUVFxf3v9+5XC5wuVx6g88H6NuXzqjAC7ggGfB4PODxeAofz2ZcAzSN7eBgLnzx\nBRdiY2mrXppvv6XDIk+fprNAAWh/PXbb6DZFY5v15F9UVOTi5ubGZ267uroWXrt2LVxyn+zsbJ/G\nxkbDwYMHp1RXV5svXLhw/dSpU3c0L0vyDdJEQQG9jJCjI07uQjJp0ngAgBUrVsh1PJtxDfAqtsvL\naShPmADw2WfSn3/HDrqdPQvQrdur+7HbBika26xnTg6H0+oZ5MbGRsObN2/2OHv27JC6ujqTvn37\nXunTp89VHx+fbJmehM+ns0ywvx+1k7aIaz4fYOhQmrzf9H7duhXgP/+hl6wICFD8NSAkifXk7+Li\nUsTn892Y23w+3435Gsxwc3Pj29ravjA2Nq43NjauHzhw4IVbt24Fy5T8CaHvmvp6TP6o3bAd10+e\nAPTpQ0/wrl0rfYx9QgLt2jl3jq4ZgxBrZDkxIM/W2Nho0KVLl0e5ubmeL1++NGrpxNj9+/f9hgwZ\nckYoFOrX1taaBAUF3bl3716A5D4g7YTv8+eEWFsTsnw5PfGLkAJAzhO+bMU1+Tu23d0JmTDhzZee\n3rCBEA8PQnJy2uZvgLSTrLHNesvfwMBAGB8fPz8yMvKUSCTSnz179hZ/f//7CQkJsQAAsbGxCX5+\nfllRUVHJ3bt3v62npyeeM2fO5oCAgEyZnqCg4NVFXHAZZ9RO2I5rPz+AXbvo6pAtWbsW4Kef6Cqe\n+AUXtQXNm+R1+DCd+lhdTTtC33qr/SuHNJ6qJ3nFxhJYvbrlmbXffktXLDl7lrZzEJKHSid5tSmc\n4IW0wOrVTS/dB0BPZ61YAbB9O23xY+JHbUnzkj+fD+DiQqc04hh/pKGYa65eukRvE0IXWdu3jyZ+\nZ2eVVg/pAM1M/mZm9OoLzOV3ENJAzBh9QugY/6QkgJQUumAtQm1N85J/QQEdF4ddPkgLEEKvR5SS\nQodz2tmpukZIV2je9Fg+n65f6+Gh6pogpJSyMoApU+jPM2dwWWXUvjQr+QuFdD2fykps+SONVloK\nMGAAXZ3z9OlX15RFqL1oVrfPkyf0ezGfj8kfabR+/QBsbWmLHxM/UgXNSv44zBNpCTs7ek0iMzNV\n1wTpKs1K/nw+Hfycn499/kijBQUBCASqrgXSZZqV/JmlHQoL6TcAhDRUS5O8EGpPmpX8+XzaQWpr\nC9Chg6prg5DCmk/yQqi9aV7yNzTELh+kFfBCLEiVNCv5FxTQ4Z54shchhJSiWcmfzweoq8PkjxBC\nStKc5F9XB1BTA1BSgskfIYSUpDnJn8+nq3gWFGCfP0IIKUlzkj9O8EIIIdZoTvJnWv58Po7xRwgh\nJWlO8i8oALC2puPjjI1VXRuEENJompP8+Xw6sQu7fBBCSGmalfwBMPkjhBALNCf5FxQANDRg8kcI\nIRZoRvInhLb8q6pwmCdCCLFAM5J/WRld0+fJE2z5I4QQCzQj+TPr+OMYf4QQYoVmJH9mghfzEyGE\nkFI0I/nz+QA2NgDm5gCmpqquDUIIaTzNSP4FBTTpY5cPQgixok2Sf3JycpSfn1+Wj49P9po1axY3\nf5zH43EtLCwqQ0ND00NDQ9NXrly59I0F8vkAenqY/JHKsR7bCKmIAdsFikQi/fnz58efOXNmqIuL\nS1Hv3r2vjx49+qi/v/99yf0GDRp0/ujRo6NlKpTPp10+OMwTqVCbxDZCKsJ6yz8tLS3M29s7x9PT\nM8/Q0LAxJiZmz5EjR95pvh8hhCNzoQUFdC1/bPkjFWqT2EZIRVhv+RcVFbm4ubnxmduurq6F165d\nC5fch8PhkMuXL/cLDg6+5eLiUvTDDz8sCggIyGxeVlxcHJ3gVVgI3IcPgTt5MtvVRTqCx+MBj8dT\nqgzWY/tvXC4XuFyuUnVDukvR2GY9+XM4HNLaPj169LjJ5/PdTExM6k6ePDk8Ojr68MOHD7s23y8u\nLg6gsBBg0yba8sduH6Sg5gl2xYoVcpfBemwjxAJFY5v1bh8XF5ciPp/vxtzm8/lurq6uhZL7mJub\nV5uYmNQBAAwfPvxkY2OjYVlZmXWLBTITvPLzMfkjlWI9thFSIdaTf69evW5kZ2f75OXleQoEAqO9\ne/dOHD169FHJfYqLix2YftG0tLQwQgjH2tq6rMUCCwoAHBwATEzoSV+EVIT12EZIhVjv9jEwMBDG\nx8fPj4yMPCUSifRnz569xd/f/35CQkIsAEBsbGzC/v37x//yyy/zDAwMhCYmJnV79uyJkVognw9g\nZoYne5HKsR7bCKkQh5BWuzFVgsPhEEIIwIIFAJWVtM//wAFVVwtpCQ6Ho7JROf+LbYTagKyxrf4z\nfPl8ALEYW/4IIcQizUj+9fWY/BFCiEWs9/mzrqAAwMICR/oghBCL1LvlX19P+/ufPcOWP0IIsUi9\nk39hIYCLC47xRwghlql38ufzARwdAYyMaNcPQgghVqh38i8oALCywlY/QgixTL2TP58P0KED9vcj\nhBDL1Hu0T0EBvYiLm1vr+yKEEJKZeid/Ph/A0BC7fRBCiGXq3+1TXY3dPgghxDL1bvkXFNCfmPwR\nQohV6t3yB6Bj/B88UHUtEEJIq6h38nd0BBAIACIjVV0ThBDSKuqd/KurAbp2BbC0VHVNEEJIq6h3\nn7+PD4A1XgEPIYTYpt4t//Jy2vWDEEKIVeqd/CMiAO7eBaioUHVNEEJIq6h38n/6FOCDDwAuXVJ1\nTRBCSKuod59/Xh5AYCBAjx6qrglCCGkV9W754zr+CCHUJtQ7+QuFdGG3pCRV1wQhhLSKeid/NzeA\npUsB+vdXdU0QQkircAghqq5DizgcDiEeHgAZGTjJC7GOw+EAIYSjoucm6vq+Q5pP1thW75b/wIGY\n+BFCqA2od/IXiXCMP0IItQH1Tv4//QTw5Zf4AYAQQixT7+RvaQnwzTcKT/Li8XhKVwHLUK86sFWG\npsP/JZahrDZJ/snJyVF+fn5ZPj4+2WvWrFksbb/r16/3NjAwEB48eHCs1MIsLQFGjFCoHuryz9CW\nMtShDmyVoQhW41pJ+L/EMpTFevIXiUT68+fPj09OTo7KzMwM2L1796T79+/7t7Tf4sWL10RFRSWr\natQFQrLCuEbahvXkn5aWFubt7Z3j6emZZ2ho2BgTE7PnyJEj7zTf78cff/x4/Pjx++3s7ErYrgNC\nbMO4RlqHEMLqtm/fvvHvv//+Zub2jh07psyfP/9HyX0KCwtduFxuilgs5syYMWPbgQMHxjYvBwAI\nbri15aaKuMbYxq09NllimvWF3TgcDmltn08++WTd6tWrl/w92YXT0tdj/MqM1AlbcQ2AsY3UA+vJ\n38XFpYjP57sxt/l8vpurq2uh5D5//fVXz5iYmD0AAC9evLA9efLkcENDw8bRo0cfZbs+CLEB4xpp\nHba7fRobGw26dOnyKDc31/Ply5dGwcHBGZmZmf7S9n/T12PccFOXDeMaN23bWG/5GxgYCOPj4+dH\nRkaeEolE+rNnz97i7+9/PyEhIRYAIDY2NoHt50SorWFcI62j6k+flraTJ09G+fr6Znl7e2evXr16\nsbzHz5w5c6u9vX1xUFDQHUXrUFBQ4MblclMCAgLuBQYG3l2/fv0Cecuor6/vGBYWdi04ODjD398/\nc8mSJd8qWh+hUKgfEhKSPnLkyGOKHO/h4ZHXrVu32yEhIem9e/dOk/f48vJyy3Hjxu338/O77+/v\nn3nlypU+8paRlZXlGxISks5snTp1qpT377pq1arPAwIC7gUFBd2ZNGnSroaGhg7y1mPdunULg4KC\n7gQGBt5dt27dQmXjVZ4NY1u94poQ5WObjbgmpP1jm9XAZmMTCoX6Xl5eObm5uZ4CgcCwta/XLW0X\nLlyIuHnzZqgyb5CnT586pqenhxBCoLq62qxr164P5K0HIQRqa2tNCKHdBuHh4VdTU1MHKFKftWvX\nfjp58uSdo0aNOqrI8Z6enrmlpaXWiv49pk2b9tuWLVtmMa+loqLCQpn/s0gk0nN0dHxaUFDgJusx\nubm5np07d37MvCnefffdvYmJidPled47d+4EBQUF3amvr+8oFAr1hw4d+mdOTo6XMq9F1g1jW/3i\nmhB2Y1uRuCZENbGtdss7yDqe+k0iIiJSraysypWph6Oj47OQkJAMAAAzM7Maf3//+0+ePHGWtxwT\nE5M6AACBQGAkEon0ra2ty+Qto7Cw0PXEiRP/eP/9938lSowUUfTYyspKi9TU1IhZs2ZtBaBdIBYW\nFpWK1gMA4MyZM0O9vLweubm58WU9plOnTlWGhoaNdXV1JkKh0KCurs7ExcWlSJ7nzcrK8gsPD7/W\nsWPHBn19fdGgQYPOt+VMXEkY202pOq4B2I9tReIaQDWxrXbJv6ioyEXyD+fq6lpYVFTkoso65eXl\neaanp4eGh4dfk/dYsVisFxISkuHg4FA8ePDglICAgEx5y/jnP//5f99///2/9fT0xPIey+BwOGTo\n0KFnevXqdWPz5s1z5Dk2Nze3s52dXcnMmTO39ejR4+acOXM219XVmShaFwCAPXv2xEyePHmXPMdY\nW1uX/etf/1rr7u5e4Ozs/MTS0rJi6NChZ+QpIygo6G5qampEWVmZdV1dnUlSUtKIwsJCV/lqrxiM\n7aZUHdcA7Me2InENoJrYVrvkL8t46vZUU1NjNn78+P3r169faGZmViPv8Xp6euKMjIyQwsJC1wsX\nLgzk8XhceY4/fvz4SHt7++ehoaHpyrRwLl261D89PT305MmTw3/66aePUlNTI2Q9VigUGty8ebPH\nhx9++PPNmzd7mJqa1q5evXqJonURCARGx44dGzVhwoR98hz36NEjr3Xr1n2Sl5fn+eTJE+eamhqz\nnTt3vidPGX5+flmLFy9e8/bbb58ePnz4ydDQ0HRlko88MLZfUYe4BmA3thWNawDVxLbaJX9ZxlO3\nl8bGRsNx48YdmDJlyu/R0dGHlSnLwsKicsSIEUk3btzoJc9xly9f7nf06NHRnTt3zp00adLuc+fO\nvTVt2rTt8j6/k5PTUwAAOzu7kjFjxhxKS0sLk/VYV1fXQldX18LevXtfBwAYP378/ps3b/aQtw6M\nkydPDu/Zs+df8i6BcOPGjV79+vW7bGNjU2pgYCAcO3bswcuXL/eT9/lnzZq19caNG73Onz8/yNLS\nssLX1/eBvGUoAmP7FXWIawB2Y1vRuAZQUWwrc6KkLTZ5x1O/6QSKMifFxGIxZ+rUqds/+eST/1O0\njJKSEtvy8nJLQgjU1dUZR0REXDhz5swQRcvj8XiDFBkVUVtba1JVVWVOCIGamhrTfv36XTp16tTb\n8pQRERFx4cGDB10JIbB8+fK4zz77bI2ir2PixIl75D2ZRQiBjIyM4MDAwLt1dXXGYrGYM23atN/i\n4+M/krec4uJie0II5Ofnu/v5+d2vrKzspOhrkWfD2G55U2VcE8JebCsa14SoJrZZCWq2txMnTgzv\n2rXrAy8vr5xVq1Z9Lu/xMTExu52cnJ4YGRm9dHV15W/dunWmvGWkpqYO4HA44uDg4AxmCNfJkyej\n5Cnj9u3b3UJDQ28GBwdndOvW7fZ33333b2X+Ljweb5AioyIeP37cOTg4OCM4ODgjMDDwriJ/04yM\njOBevXpd7969+60xY8YcVHRERE1NjamNjc0L5k0r77ZmzZrPmOFw06ZN+00gEBjKW0ZERMSFgICA\ne8HBwRnnzp0brGy8yrNhbKtXXBPCTmwrG9eEtH9sq+0F3BFCCLUdtevzRwgh1PYw+SOEkA7C5I8Q\nQjoIkz9CCOkgTP4q0r9//0sAAPn5+R67d++exGbZq1at+qKl50KoPbVnjCP54WgfFePxeNy1a9f+\n69ixY6NkPUYoFBoYGBgIpT1ubm5eXV1dbc5ODRFSjjrEOPl7FrG6zbJWKUXHpOKm3GZqalpDCIHw\n8PCrFhYWFSEhIenr1q1bKBKJ9BYtWvR9796907p3734rISFhLiEEUlJSuAMGDEgdPXr0EV9f3yxC\nCLzzzjuHe/bseSMwMPDupk2b5hBCYPHixav19fWFISEh6VOmTNkh+VxisZizaNGi74OCgu5069bt\n9t69e99lyh40aBBv/Pjx+/z8/O6/9957v6v674Ob5m/tGeNr1679NCgo6E5QUNAdZinj3Nxcz65d\nuz6YNm3ab4GBgXflXWlT2zeVV0BXNzMzs2pCXp/dmJCQMHflypVfEkKgoaGhQ69eva7n5uZ6pqSk\ncE1NTWvy8vI8mH3LysqsCKEzLIOCgu4wt5mymz/X/v37xw0bNuy0WCzmFBcX27u7u+c/ffrUMSUl\nhWthYVFRVFTkLBaLOX379r188eLF/qr+G+Gm2Vt7xfiNGzd6duvW7XZdXZ1xTU2NaWBg4N309PSQ\n3NxcTz09PdG1a9fCVP23UMcN+/xVjDRb1Or06dNvb9++fVpoaGh6nz59rpaVlVnn5OR4AwCEhYWl\neXh45DP7rl+/fmFISEhG3759r/D5fLfs7GyfNz3XxYsXB0yePHkXh8Mh9vb2zwcNGnT++vXrvTkc\nDgkLC0tzdnZ+wuFwSEhISEZeXp5nm7xgpHPaOsYvXrw4YOzYsQeNjY3rTU1Na8eOHXswNTU1gsPh\nEA8Pj/ywsLC0tn+Vmof1yzgi5cXHx88fNmzYn5L38Xg8rqmpaa3k7bNnzw65evVqn44dOzYMHjw4\npaGhoeObyuVwOKT5G5HpA+3QocNL5j59fX2RUCjE2EBths0Ybx7XhBAOE9eS5aGmsOWvYs1PXEVG\nRp76+eefP2SS78OHD7u2tL54VVVVJysrq/KOHTs2ZGVl+V29erUP85ihoWFjS8k7IiIide/evRPF\nYrFeSUmJ3YULFwaGhYWlNf9AQIhNbR3jERERqYcPH46ur683rq2tNT18+HB0REREKsb1m2HrTkWY\nlklwcPAtfX19UUhISMbMmTO3LViwYENeXp5njx49bhJCOPb29s8PHTo0hsPhEMmRClFRUckbN278\nIF/L7vYAAACVSURBVCAgINPX1/dB3759rzCPzZ07d1P37t1v9+zZ868dO3ZMZY4bM2bMoStXrvQN\nDg6+xeFwyPfff/9ve3v75/fv3/dvPgoCR0UgZbVnjM+YMSOR6d6ZM2fO5uDg4Ft5eXmeGMfS4VBP\nhBDSQdjtgxBCOgiTP0II6SBM/gghpIMw+SOEkA7C5I8QQjoIkz9CCOmg/wcPXjxTXSoyfAAAAABJ\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x12e061a50>"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "print 'Train ---100'\n",
      "tr_all = train(100)\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,yourFeatures,alltags,'perc')\n",
      "\n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'With Cluster'\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,clusterFeatures,alltags,'perc')\n",
      "# this code makes plots of the training and development set accuracy\n",
      "makePlots(tr_acc,dv_acc)\n",
      "\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train ---100\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.640887414472 train: 0.522442972774\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.680074642339 train: 0.81604120677\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.694173750778 train: 0.889624724062\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.693759071118 train: 0.93451066961\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.699564586357 train: 0.93451066961\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.700186605847 train: 0.943340691685\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.702260004147 train: 0.949227373068\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.701015965167 train: 0.956585724798\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.700393945677 train: 0.970566593083\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.698735227037 train: 0.966151582046\n",
        "With Cluster"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.67198838897 train: 0.543046357616\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.702260004147 train: 0.857983811626\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.711590296496 train: 0.913907284768\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.714078374456 train: 0.952906548933\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.715115073606 train: 0.959529065489\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.714285714286 train: 0.965415746873\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.713249015136 train: 0.966151582046\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.713041675306 train: 0.974245768948\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.710553597346 train: 0.978660779985\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.711590296496 train: 0.983811626196\n",
        "Train ---200\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.703504043127 train: 0.589622641509\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.736885755754 train: 0.814223512337\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.745179348953 train: 0.879172714078\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.746838067593 train: 0.91618287373\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.746423387933 train: 0.92053701016\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.744764669293 train: 0.931059506531\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.743313290483 train: 0.940130624093\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.742069251503 train: 0.945936139332\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.742483931163 train: 0.948113207547\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.742898610823 train: 0.949564586357\n",
        "With Cluster"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.721749948165 train: 0.604499274311\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.749533485383 train: 0.83671988389\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.750777524362 train: 0.907111756168\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.755961020112 train: 0.924528301887\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.756168359942 train: 0.945210449927\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.753058262492 train: 0.955007256894\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.753887621812 train: 0.958998548621\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.752850922662 train: 0.96915820029\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.752228903172 train: 0.969883889695\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.753472942152 train: 0.96915820029\n",
        "Train ---500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.759485797222 train: 0.654867256637\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.786647314949 train: 0.82043962318\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.795977607298 train: 0.87382243791\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.799295044578 train: 0.903225806452\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.799087704748 train: 0.918355695118\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.799917064068 train: 0.921067656295\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.801161103048 train: 0.924778761062\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.801575782708 train: 0.928204396232\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.801161103048 train: 0.933057379389\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.801368442878 train: 0.934341992578\n",
        "With Cluster"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.785195936139 train: 0.675849272053\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.800124403898 train: 0.833856694262\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.800331743728 train: 0.892520696546\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.804271200498 train: 0.91478732515\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.804063860668 train: 0.927918926634\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.804685880158 train: 0.934770196974\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.805307899648 train: 0.942763345704\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.800746423388 train: 0.949614616043\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.800539083558 train: 0.949186411647\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.799087704748 train: 0.954182129603\n",
        "Train ---1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.798258345428 train: 0.695327997811\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.816296910637 train: 0.823996169369\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.824175824176 train: 0.868458854915\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.829151980095 train: 0.890621793556\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.830188679245 train: 0.899445926534\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.829566659755 train: 0.9047814488\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.831847397885 train: 0.914426431356\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.830188679245 train: 0.915178876804\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.830396019075 train: 0.919009508174\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.828944640265 train: 0.920993227991\n",
        "With Cluster"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.815052871657 train: 0.713660305082\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.830603358905 train: 0.840276352692\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.832262077545 train: 0.883644572132\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.833298776695 train: 0.903002941378\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.832469417375 train: 0.915247280936\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.836201534315 train: 0.924481838703\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.835994194485 train: 0.930227785758\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.837445573295 train: 0.941446063342\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.835579514825 train: 0.941035638553\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dev: 0.834750155505 train: 0.94431903687\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEVCAYAAAAIK+VbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGoLiDwAA0xAUfwAAmIag+AMAwDT0b+S+m5WgpinEAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x12df5da50>"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   \n",
      "print 'Train ---200'\n",
      "tr_all = train(200)\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,yourFeatures,alltags,'perc')\n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'With Cluster'\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,clusterFeatures,alltags,'perc')\n",
      "# this code makes plots of the training and development set accuracy\n",
      "makePlots(tr_acc,dv_acc)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "    \n",
      "print 'Train ---500'\n",
      "tr_all = train(500)\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,yourFeatures,alltags,'perc')\n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'With Cluster'\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,clusterFeatures,alltags,'perc')\n",
      "# this code makes plots of the training and development set accuracy\n",
      "makePlots(tr_acc,dv_acc)\n",
      "\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   \n",
      "print 'Train ---1000'\n",
      "tr_all = train(1000)\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,yourFeatures,alltags,'perc')\n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'With Cluster'\n",
      "w, tr_acc, dv_acc = trainAvgPerceptron(10,tr_all,clusterFeatures,alltags,'perc')\n",
      "# this code makes plots of the training and development set accuracy\n",
      "makePlots(tr_acc,dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You may want to try larger numbers of clusters to improve performance. \n",
      "\n",
      "You can even include the results from multiple clusterings with different numbers of clusters (50, 100, 200, 500, ...), \n",
      "using features like C43-50/N (cluster 43 of 50, with tag N), C377-500/V (cluster 377 of 500, with tag V).\n",
      "\n",
      "You can also use clusters for the features of neighboring words."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7.2 Dependency Parser ###\n",
      "\n",
      "If you could not get your implementation of structured perceptron for Twitter POS tagging to work, \n",
      "and you don\u2019t want to keep trying, you can instead add distributional features to the dependency parser from homework 3.\n",
      "\n",
      "Download the Brown clusters from a [word representation website](http://metaoptimize.com/projects/wordreprs/), \n",
      "using the 1000-cluster model. Follow [this paper](http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf) on word representation, \n",
      "adding features for prefixes of length 4, 6, 10, and 20. \n",
      "The features should capture the prefix of the head and modifier. You may also try \u201chybrid\u201d \n",
      "features that combine a prefix for the head, and the POS tag of  the modifier - and vice versa. \n",
      "See [this paper](http://www.cs.columbia.edu/~mcollins/papers/koo08acl.pdf) for more ideas and details.\n",
      "\n",
      "**Deliverable 11 (Option B)** Building training sets including the first 100, 500, 1000, 3000, and 7596 **sentences** (not words).\n",
      "Train your parser on each training set, using your best features, and plot the dev set accuracy. Then retrain your parser, adding \n",
      "the new Brown cluster features. Plot dev set accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Your code here\n",
      "'''\n",
      "from numpy import sign\n",
      "import sys\n",
      "sys.path.append('parsing/')\n",
      "\n",
      "import dependency_parser as depp\n",
      "import dependency_features as depf\n",
      "\n",
      "class LexFeats(depf.DependencyFeatures):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "        ff = super(LexFeats,self).create_arc_features(instance,h,m,add)\n",
      "        k = len(ff)\n",
      "        f = self.getF((k,instance.pos[h],instance.words[m]),add)\n",
      "        ff.append(f)\n",
      "       \n",
      "        return ff\n",
      "class LexDistFeats(LexFeats):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "        ff = super(LexDistFeats,self).create_arc_features(instance,h,m,add)\n",
      "        k = len(ff)\n",
      "        if(abs(h-m) <=10 ) :\n",
      "            f = self.getF((k,h-m), add) # your code here\n",
      "            ff.append(f)\n",
      "        return ff\n",
      "class LexDistFeats2(LexDistFeats):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "           ff = super(LexDistFeats2,self).create_arc_features(instance,h,m,add)\n",
      "           k = len(ff)\n",
      "           f = self.getF((k,instance.words[h],instance.pos[m]),add)\n",
      "           ff.append(f)\n",
      "           return ff\n",
      "class ContextFeats(LexDistFeats2):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "         ff = super(ContextFeats,self).create_arc_features(instance,h,m,add)\n",
      "         k = len(ff)\n",
      "         if(h>1):\n",
      "             f = self.getF((k,instance.pos[h],instance.pos[h-1],instance.pos[m]),add)\n",
      "             ff.append(f) \n",
      "         if(m < len(instance.pos)-1):\n",
      "             f1 = self.getF((k,instance.pos[h],instance.pos[m],instance.pos[m+1]),add)\n",
      "             ff.append(f1)\n",
      "         if(m>1):\n",
      "             f = self.getF((k,instance.pos[h],instance.pos[m],instance.pos[m-1]),add)\n",
      "             ff.append(f) \n",
      "         return ff\n",
      "class BakeOffFeats(ContextFeats):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "         ff = super(BakeOffFeats,self).create_arc_features(instance,h,m,add)\n",
      "         k = len(ff)\n",
      "         if(h>1):\n",
      "             f = self.getF((k,instance.words[h],instance.words[h-1]),add)\n",
      "             ff.append(f)\n",
      "        \n",
      "         if(h>1) and m < len(instance.pos)-1: \n",
      "             f1 = self.getF((k,instance.pos[h],instance.pos[h-1],instance.pos[m],instance.pos[m+1]),add)\n",
      "             ff.append(f1)\n",
      "      #   f1 = self.getF((k,instance.words[h],instance.words[m],instance.pos[h],instance.pos[m]),add)\n",
      "      #   ff.append(f1) \n",
      "         \n",
      "         #for i in range(len(instance.words)):\n",
      "       #     if instance.pos[i] == instance.pos[m] :\n",
      "       #          f1 = self.getF((k,instance.words[h],instance.words[i]),add)\n",
      "       #          ff.append(f1) \n",
      "                            \n",
      "         return ff\n",
      "\n",
      "\n",
      "                \n",
      "                \n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",8000)    \n",
      "brown_weights = defaultdict()\n",
      "word_weights = defaultdict()\n",
      "with open('brown.txt','rb') as vocabfile:\n",
      "        for line in vocabfile:\n",
      "            split = line.split()\n",
      "            if None != dp.reader.word_dict.get(split[1]):\n",
      "                brown_weights[dp.reader.word_dict.get(split[1])] = split[0]\n",
      "                word_weights[dp.reader.word_dict.get(split[1])] = split[1]\n",
      "                \n",
      "class BrownFeats(BakeOffFeats):\n",
      "    def create_arc_features(self,instance,h,m,add=False):\n",
      "         ff = super(BrownFeats,self).create_arc_features(instance,h,m,add)\n",
      "         k = len(ff)\n",
      "         headp = brown_weights.get(instance.words[h])\n",
      "         mop= brown_weights.get(instance.words[m])\n",
      "         if None!= headp  and None != mop:\n",
      "                f1 = self.getF((k,headp,mop),add)\n",
      "                ff.append(f1)\n",
      "                if(len(headp) > 4 and len(mop)>4):\n",
      "                   f1 = self.getF((k,headp[0:4],mop[0:4]),add)\n",
      "                   ff.append(f1)\n",
      "                #   f1 = self.getF((k,headp[0:4],instance.pos[h]),add)\n",
      "                #   ff.append(f1)\n",
      "             #      f1 = self.getF((k,headp[0:4],word_weights[instance.words[m]]),add)\n",
      "             #      ff.append(f1)\n",
      "             #      f1 = self.getF((k,mop[0:4],word_weights[instance.words[h]]),add)\n",
      "             #      ff.append(f1)\n",
      "                #   f1 = self.getF((k,mop[0:4],instance.pos[m]),add)\n",
      "                #   ff.append(f1)\n",
      "                if(len(headp) > 6 and len(mop)>6):\n",
      "                   f1 = self.getF((k,headp[0:6],mop[0:6]),add)\n",
      "                   ff.append(f1)\n",
      "                if(len(headp) > 10 and len(mop)>10):\n",
      "                   f1 = self.getF((k,headp[0:10],mop[0:10]),add)\n",
      "                   ff.append(f1)\n",
      "                if(len(headp) > 20 and len(mop)>20):\n",
      "                   f1 = self.getF((k,headp[0:20],mop[0:20]),add)\n",
      "                   ff.append(f1)\n",
      "             #      f1 = self.getF((k,headp[0:6],word_weights[instance.words[m]]),add)\n",
      "             #      ff.append(f1)\n",
      "             #      f1 = self.getF((k,mop[0:6],word_weights[instance.words[h]]),add)\n",
      "             #      ff.append(f1)\n",
      "                 #  f1 = self.getF((k,headp[0:6],instance.pos[h]),add)\n",
      "                 #  ff.append(f1)\n",
      "                 #  f1 = self.getF((k,mop[0:6],instance.pos[m]),add)\n",
      "                 #  ff.append(f1)\n",
      "              #  for i in range(len(instance.words)):\n",
      "              #      if instance.pos[i] == instance.pos[m] :\n",
      "              #           f1 = self.getF((k,word_weights[instance.words[h]],word_weights[instance.words[m]]),add)\n",
      "              #           ff.append(f1) \n",
      "                                     \n",
      "         return ff\n",
      "                \n",
      "#wordid = dp.reader.word_dict['best']\n",
      "#print brown_weights[dp.reader.word_dict['best']][0:6]\n",
      "#print word_weights[wordid]\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "parsing/../data/deppars\n",
        "Number of sentences: 7569"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of tokens: 75621\n",
        "Number of words: 11766\n",
        "Number of pos: 48\n",
        "Number of features: 96518"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Train 100'\n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",100)\n",
      "tr_acc ,dv_acc  = dp.train_perceptron(10) \n",
      "makePlots(tr_acc,dv_acc)\n",
      "print 'Cluster Features'\n",
      "dp = depp.DependencyParser(feature_function=BrownFeats())\n",
      "dp.read_data(\"english\",100)\n",
      "tr_acc , dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc,dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Train 100\n",
        "parsing/../data/deppars\n",
        "Number of sentences: 100\n",
        "Number of tokens: 975\n",
        "Number of words: 524\n",
        "Number of pos: 37\n",
        "Number of features: 30760"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.761 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.787\n",
        "[0.7605361221300637]\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'makePlots' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-c155e356be95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdv_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmakePlots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdv_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Cluster Features'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDependencyParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBrownFeats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'makePlots' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "110111\n",
        "best\n"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Train 500'\n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",500)\n",
      "tr_acc , dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc, dv_acc)\n",
      "print 'Cluster Features'\n",
      "dp = depp.DependencyParser(feature_function=BrownFeats())\n",
      "dp.read_data(\"english\",500)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc , dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Train 3000'\n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",3000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10)  \n",
      "makePlots(tr_acc, dv_acc)\n",
      "print 'Cluster Features'\n",
      "dp = depp.DependencyParser(feature_function=BrownFeats())\n",
      "dp.read_data(\"english\",3000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc, dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "parsing/../data/deppars\n",
        "Number of sentences: 7569"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of tokens: 75621\n",
        "Number of words: 11766\n",
        "Number of pos: 48\n",
        "Number of features: 131335"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.772 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.810\n",
        "Epoch 2 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.855 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.834\n",
        "Epoch 3 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.889 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.846\n",
        "Epoch 4 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.910 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.852\n",
        "Epoch 5 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.927 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.858\n",
        "Epoch 6 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.936 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.860\n",
        "Epoch 7 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.945 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.863\n",
        "Epoch 8 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.952 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.865\n",
        "Epoch 9 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.957 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.867\n",
        "Epoch 10 Train: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.962 Dev: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.866\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Train 5000'\n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",5000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10)  \n",
      "makePlots(tr_acc, dv_acc)\n",
      "print 'Cluster Features'\n",
      "dp = depp.DependencyParser(feature_function=BrownFeats())\n",
      "dp.read_data(\"english\",5000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc, dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Train 8000'\n",
      "dp = depp.DependencyParser(feature_function=BakeOffFeats())\n",
      "dp.read_data(\"english\",8000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10)  \n",
      "makePlots(tr_acc, dv_acc)\n",
      "print 'Cluster Features'\n",
      "dp = depp.DependencyParser(feature_function=BrownFeats())\n",
      "dp.read_data(\"english\",8000)\n",
      "tr_acc, dv_acc = dp.train_perceptron(10) \n",
      "makePlots(tr_acc, dv_acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}